[2020-12-29 13:08:04,313] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-12-29 13:08:04,315] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-12-29 13:08:04,315] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-12-29 13:08:04,315] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-12-29 13:08:04,319] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-12-29 13:08:04,330] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-12-29 13:08:04,334] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-12-29 13:08:04,363] INFO Server environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:08:04,364] INFO Server environment:host.name=192.168.0.230 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:08:04,364] INFO Server environment:java.version=11.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:08:04,364] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:08:04,364] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:08:04,364] INFO Server environment:java.class.path=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\activation-1.1.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\argparse4j-0.7.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\audience-annotations-0.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\commons-cli-1.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\commons-lang3-3.8.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-api-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-basic-auth-extension-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-file-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-json-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-mirror-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-mirror-client-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-runtime-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-transforms-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\hk2-api-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\hk2-locator-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\hk2-utils-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-annotations-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-core-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-databind-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.inject-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javassist-3.22.0-CR2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javassist-3.26.0-GA.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javax.servlet-api-3.1.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jaxb-api-2.3.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-client-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-common-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-container-servlet-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-hk2-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-media-jaxb-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-server-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jopt-simple-5.0.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-clients-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-log4j-appender-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-examples-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-scala_2.13-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-test-utils-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-tools-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-javadoc.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-scaladoc.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-sources.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-test-sources.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-test.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\log4j-1.2.17.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\lz4-java-1.7.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\maven-artifact-3.6.3.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\metrics-core-2.2.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-buffer-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-codec-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-common-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-handler-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-resolver-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-transport-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-transport-native-epoll-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-transport-native-unix-common-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\paranamer-2.8.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\plexus-utils-3.2.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\reflections-0.9.12.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\rocksdbjni-5.18.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-collection-compat_2.13-2.1.6.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-java8-compat_2.13-0.9.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-library-2.13.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-reflect-2.13.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\slf4j-api-1.7.30.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\snappy-java-1.1.7.3.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\validation-api-2.0.1.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\zookeeper-3.5.8.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\zookeeper-jute-3.5.8.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:08:04,367] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.2\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\development\version control\Git\cmd;D:\Software\posgres\pg11\bin;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\Gpg4win\..\GnuPG\bin;C:\Program Files\PuTTY\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.2\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\Daglemino\AppData\Local\Microsoft\WindowsApps;C:\tools\cuda\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\include;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\extra\CUPTI\libx;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:08:04,368] INFO Server environment:java.io.tmpdir=C:\Users\DAGLEM~1\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:08:04,368] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:08:04,368] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:08:04,369] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:08:04,369] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:08:04,370] INFO Server environment:user.name=Daglemino (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:08:04,370] INFO Server environment:user.home=C:\Users\Daglemino (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:08:04,371] INFO Server environment:user.dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:08:04,375] INFO Server environment:os.memory.free=493MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:08:04,375] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:08:04,376] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:08:04,381] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:08:04,390] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:08:04,391] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir data\zookeeper\version-2 snapdir data\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:08:04,412] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-12-29 13:08:04,417] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 24 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-12-29 13:08:04,422] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-12-29 13:08:04,441] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-12-29 13:08:04,453] INFO Reading snapshot data\zookeeper\version-2\snapshot.90 (org.apache.zookeeper.server.persistence.FileSnap)
[2020-12-29 13:08:04,492] INFO Snapshotting: 0xb3 to data\zookeeper\version-2\snapshot.b3 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-12-29 13:08:04,527] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-12-29 13:08:18,580] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-12-29 13:08:18,891] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-12-29 13:08:18,964] INFO starting (kafka.server.KafkaServer)
[2020-12-29 13:08:18,965] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-12-29 13:08:18,989] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-12-29 13:08:19,006] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:08:19,007] INFO Client environment:host.name=192.168.0.230 (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:08:19,007] INFO Client environment:java.version=11.0.2 (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:08:19,007] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:08:19,007] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.2 (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:08:19,007] INFO Client environment:java.class.path=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\activation-1.1.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\argparse4j-0.7.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\audience-annotations-0.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\commons-cli-1.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\commons-lang3-3.8.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-api-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-basic-auth-extension-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-file-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-json-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-mirror-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-mirror-client-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-runtime-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-transforms-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\hk2-api-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\hk2-locator-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\hk2-utils-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-annotations-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-core-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-databind-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.inject-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javassist-3.22.0-CR2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javassist-3.26.0-GA.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javax.servlet-api-3.1.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jaxb-api-2.3.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-client-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-common-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-container-servlet-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-hk2-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-media-jaxb-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-server-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jopt-simple-5.0.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-clients-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-log4j-appender-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-examples-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-scala_2.13-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-test-utils-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-tools-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-javadoc.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-scaladoc.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-sources.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-test-sources.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-test.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\log4j-1.2.17.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\lz4-java-1.7.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\maven-artifact-3.6.3.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\metrics-core-2.2.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-buffer-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-codec-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-common-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-handler-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-resolver-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-transport-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-transport-native-epoll-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-transport-native-unix-common-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\paranamer-2.8.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\plexus-utils-3.2.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\reflections-0.9.12.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\rocksdbjni-5.18.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-collection-compat_2.13-2.1.6.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-java8-compat_2.13-0.9.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-library-2.13.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-reflect-2.13.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\slf4j-api-1.7.30.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\snappy-java-1.1.7.3.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\validation-api-2.0.1.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\zookeeper-3.5.8.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\zookeeper-jute-3.5.8.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:08:19,011] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.2\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\development\version control\Git\cmd;D:\Software\posgres\pg11\bin;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\Gpg4win\..\GnuPG\bin;C:\Program Files\PuTTY\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.2\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\Daglemino\AppData\Local\Microsoft\WindowsApps;C:\tools\cuda\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\include;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\extra\CUPTI\libx;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:08:19,012] INFO Client environment:java.io.tmpdir=C:\Users\DAGLEM~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:08:19,012] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:08:19,012] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:08:19,013] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:08:19,013] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:08:19,014] INFO Client environment:user.name=Daglemino (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:08:19,022] INFO Client environment:user.home=C:\Users\Daglemino (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:08:19,024] INFO Client environment:user.dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:08:19,025] INFO Client environment:os.memory.free=1013MB (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:08:19,025] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:08:19,025] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:08:19,029] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@55322aab (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:08:19,041] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-12-29 13:08:19,049] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-12-29 13:08:19,052] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-12-29 13:08:19,061] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-12-29 13:08:19,065] INFO Socket connection established, initiating session, client: /127.0.0.1:57243, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-12-29 13:08:19,074] INFO Creating new log file: log.b4 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-12-29 13:08:19,086] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10008ef42590000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2020-12-29 13:08:19,090] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-12-29 13:08:19,378] INFO Cluster ID = faeabPsTRvy-g5J7XJiYXg (kafka.server.KafkaServer)
[2020-12-29 13:08:19,444] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.6-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = data\kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.6-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-12-29 13:08:19,456] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.6-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = data\kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.6-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-12-29 13:08:19,497] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-12-29 13:08:19,497] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-12-29 13:08:19,508] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-12-29 13:08:19,557] INFO Loading logs from log dirs ArraySeq(D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:19,561] INFO Attempting recovery for all logs in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka since no clean shutdown file was found (kafka.log.LogManager)
[2020-12-29 13:08:19,636] INFO [Log partition=travelportal.readers-0, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:19,638] INFO [Log partition=travelportal.readers-0, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:19,774] INFO [Log partition=travelportal.readers-0, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:19,783] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\travelportal.readers-0, topic=travelportal.readers, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 197ms (1/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:19,786] INFO [Log partition=__consumer_offsets-0, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:19,786] INFO [Log partition=__consumer_offsets-0, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:19,894] INFO [Log partition=__consumer_offsets-0, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:19,897] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-0, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 113ms (2/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:19,898] INFO [Log partition=__consumer_offsets-1, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:19,899] INFO [Log partition=__consumer_offsets-1, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:20,006] INFO [Log partition=__consumer_offsets-1, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:20,010] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-1, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 114ms (3/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:20,014] INFO [Log partition=__consumer_offsets-10, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:20,014] INFO [Log partition=__consumer_offsets-10, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:20,123] INFO [Log partition=__consumer_offsets-10, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:20,127] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-10, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 116ms (4/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:20,130] INFO [Log partition=__consumer_offsets-11, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:20,131] INFO [Log partition=__consumer_offsets-11, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:20,240] INFO [Log partition=__consumer_offsets-11, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:20,243] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-11, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 115ms (5/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:20,246] INFO [Log partition=__consumer_offsets-12, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:20,246] INFO [Log partition=__consumer_offsets-12, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:20,363] INFO [Log partition=__consumer_offsets-12, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:20,365] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-12, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 122ms (6/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:20,369] INFO [Log partition=__consumer_offsets-13, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:20,369] INFO [Log partition=__consumer_offsets-13, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:20,477] INFO [Log partition=__consumer_offsets-13, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:20,479] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-13, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 113ms (7/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:20,482] INFO [Log partition=__consumer_offsets-14, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:20,482] INFO [Log partition=__consumer_offsets-14, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:20,587] INFO [Log partition=__consumer_offsets-14, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:20,590] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-14, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 112ms (8/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:20,593] INFO [Log partition=__consumer_offsets-15, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:20,593] INFO [Log partition=__consumer_offsets-15, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:20,703] INFO [Log partition=__consumer_offsets-15, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:20,706] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-15, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 115ms (9/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:20,710] INFO [Log partition=__consumer_offsets-16, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:20,710] INFO [Log partition=__consumer_offsets-16, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:20,829] INFO [Log partition=__consumer_offsets-16, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:20,831] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-16, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 125ms (10/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:20,835] INFO [Log partition=__consumer_offsets-17, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:20,835] INFO [Log partition=__consumer_offsets-17, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:20,962] INFO [Log partition=__consumer_offsets-17, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:20,965] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-17, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 132ms (11/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:20,968] INFO [Log partition=__consumer_offsets-18, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:20,968] INFO [Log partition=__consumer_offsets-18, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:21,078] INFO [Log partition=__consumer_offsets-18, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:21,080] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-18, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 115ms (12/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:21,083] INFO [Log partition=__consumer_offsets-19, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:21,087] INFO [Log partition=__consumer_offsets-19, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:21,194] INFO [Log partition=__consumer_offsets-19, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:21,196] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-19, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 116ms (13/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:21,199] INFO [Log partition=__consumer_offsets-2, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:21,199] INFO [Log partition=__consumer_offsets-2, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:21,304] INFO [Log partition=__consumer_offsets-2, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:21,306] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-2, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 110ms (14/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:21,310] INFO [Log partition=__consumer_offsets-20, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:21,312] INFO [Log partition=__consumer_offsets-20, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:21,417] INFO [Log partition=__consumer_offsets-20, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:21,419] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-20, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 112ms (15/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:21,421] INFO [Log partition=__consumer_offsets-21, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:21,422] INFO [Log partition=__consumer_offsets-21, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:21,525] INFO [Log partition=__consumer_offsets-21, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:21,527] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-21, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 107ms (16/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:21,530] INFO [Log partition=__consumer_offsets-22, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:21,530] INFO [Log partition=__consumer_offsets-22, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:21,634] INFO [Log partition=__consumer_offsets-22, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:21,636] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-22, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 108ms (17/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:21,639] INFO [Log partition=__consumer_offsets-23, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:21,640] INFO [Log partition=__consumer_offsets-23, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:21,750] INFO [ProducerStateManager partition=__consumer_offsets-23] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2020-12-29 13:08:21,763] INFO [Log partition=__consumer_offsets-23, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:21,764] INFO [ProducerStateManager partition=__consumer_offsets-23] Loading producer state from snapshot file 'D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-23\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2020-12-29 13:08:21,772] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-23, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments in 136ms (18/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:21,775] INFO [Log partition=__consumer_offsets-24, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:21,775] INFO [Log partition=__consumer_offsets-24, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:21,884] INFO [Log partition=__consumer_offsets-24, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:21,886] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-24, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 113ms (19/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:21,889] INFO [Log partition=__consumer_offsets-25, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:21,889] INFO [Log partition=__consumer_offsets-25, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:21,998] INFO [Log partition=__consumer_offsets-25, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:22,000] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-25, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 113ms (20/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:22,003] INFO [Log partition=__consumer_offsets-26, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:22,003] INFO [Log partition=__consumer_offsets-26, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:22,114] INFO [Log partition=__consumer_offsets-26, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:22,117] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-26, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 117ms (21/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:22,120] INFO [Log partition=__consumer_offsets-27, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:22,121] INFO [Log partition=__consumer_offsets-27, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:22,226] INFO [Log partition=__consumer_offsets-27, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:22,228] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-27, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 111ms (22/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:22,230] INFO [Log partition=__consumer_offsets-28, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:22,231] INFO [Log partition=__consumer_offsets-28, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:22,335] INFO [Log partition=__consumer_offsets-28, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:22,337] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-28, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 109ms (23/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:22,340] INFO [Log partition=__consumer_offsets-29, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:22,341] INFO [Log partition=__consumer_offsets-29, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:22,457] INFO [Log partition=__consumer_offsets-29, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:22,459] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-29, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 122ms (24/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:22,462] INFO [Log partition=__consumer_offsets-3, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:22,462] INFO [Log partition=__consumer_offsets-3, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:22,565] INFO [Log partition=__consumer_offsets-3, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:22,567] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-3, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 107ms (25/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:22,569] INFO [Log partition=__consumer_offsets-30, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:22,570] INFO [Log partition=__consumer_offsets-30, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:22,679] INFO [Log partition=__consumer_offsets-30, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:22,682] INFO Expiring session 0x100047be9ff0001, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:08:22,680] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-30, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 112ms (26/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:22,685] INFO [Log partition=__consumer_offsets-31, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:22,685] INFO [Log partition=__consumer_offsets-31, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:22,797] INFO [Log partition=__consumer_offsets-31, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:22,800] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-31, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 118ms (27/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:22,803] INFO [Log partition=__consumer_offsets-32, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:22,803] INFO [Log partition=__consumer_offsets-32, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:22,907] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2020-12-29 13:08:22,914] INFO [Log partition=__consumer_offsets-32, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:22,914] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file 'D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-32\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2020-12-29 13:08:22,918] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-32, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments in 118ms (28/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:22,924] INFO [Log partition=__consumer_offsets-33, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:22,924] INFO [Log partition=__consumer_offsets-33, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:23,028] INFO [Log partition=__consumer_offsets-33, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:23,031] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-33, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 112ms (29/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:23,034] INFO [Log partition=__consumer_offsets-34, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:23,039] INFO [Log partition=__consumer_offsets-34, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:23,146] INFO [Log partition=__consumer_offsets-34, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:23,147] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-34, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 117ms (30/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:23,150] INFO [Log partition=__consumer_offsets-35, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:23,150] INFO [Log partition=__consumer_offsets-35, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:23,255] INFO [Log partition=__consumer_offsets-35, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:23,256] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-35, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 108ms (31/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:23,258] INFO [Log partition=__consumer_offsets-36, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:23,259] INFO [Log partition=__consumer_offsets-36, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:23,362] INFO [Log partition=__consumer_offsets-36, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:23,364] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-36, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 108ms (32/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:23,366] INFO [Log partition=__consumer_offsets-37, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:23,366] INFO [Log partition=__consumer_offsets-37, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:23,474] INFO [Log partition=__consumer_offsets-37, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:23,476] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-37, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 111ms (33/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:23,479] INFO [Log partition=__consumer_offsets-38, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:23,479] INFO [Log partition=__consumer_offsets-38, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:23,589] INFO [Log partition=__consumer_offsets-38, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:23,591] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-38, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 115ms (34/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:23,593] INFO [Log partition=__consumer_offsets-39, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:23,593] INFO [Log partition=__consumer_offsets-39, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:23,701] INFO [Log partition=__consumer_offsets-39, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:23,702] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-39, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 111ms (35/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:23,705] INFO [Log partition=__consumer_offsets-4, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:23,706] INFO [Log partition=__consumer_offsets-4, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:23,810] INFO [Log partition=__consumer_offsets-4, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:23,811] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-4, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 108ms (36/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:23,814] INFO [Log partition=__consumer_offsets-40, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:23,814] INFO [Log partition=__consumer_offsets-40, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:23,917] INFO [Log partition=__consumer_offsets-40, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:23,919] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-40, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 109ms (37/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:23,922] INFO [Log partition=__consumer_offsets-41, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:23,922] INFO [Log partition=__consumer_offsets-41, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:24,029] INFO [Log partition=__consumer_offsets-41, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:24,030] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-41, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 111ms (38/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:24,033] INFO [Log partition=__consumer_offsets-42, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:24,033] INFO [Log partition=__consumer_offsets-42, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:24,138] INFO [Log partition=__consumer_offsets-42, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:24,140] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-42, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 109ms (39/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:24,142] INFO [Log partition=__consumer_offsets-43, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:24,142] INFO [Log partition=__consumer_offsets-43, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:24,246] INFO [Log partition=__consumer_offsets-43, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:24,249] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-43, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 108ms (40/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:24,252] INFO [Log partition=__consumer_offsets-44, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:24,252] INFO [Log partition=__consumer_offsets-44, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:24,359] INFO [Log partition=__consumer_offsets-44, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:24,361] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-44, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 113ms (41/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:24,364] INFO [Log partition=__consumer_offsets-45, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:24,368] INFO [Log partition=__consumer_offsets-45, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:24,473] INFO [Log partition=__consumer_offsets-45, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:24,475] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-45, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 113ms (42/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:24,478] INFO [Log partition=__consumer_offsets-46, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:24,478] INFO [Log partition=__consumer_offsets-46, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:24,582] INFO [Log partition=__consumer_offsets-46, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:24,584] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-46, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 108ms (43/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:24,590] INFO [Log partition=__consumer_offsets-47, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:24,590] INFO [Log partition=__consumer_offsets-47, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:24,695] INFO [Log partition=__consumer_offsets-47, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:24,696] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-47, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 108ms (44/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:24,698] INFO [Log partition=__consumer_offsets-48, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:24,698] INFO [Log partition=__consumer_offsets-48, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:24,803] INFO [Log partition=__consumer_offsets-48, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:24,804] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-48, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 107ms (45/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:24,807] INFO [Log partition=__consumer_offsets-49, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:24,807] INFO [Log partition=__consumer_offsets-49, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:24,915] INFO [Log partition=__consumer_offsets-49, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:24,917] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-49, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 114ms (46/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:24,920] INFO [Log partition=__consumer_offsets-5, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:24,921] INFO [Log partition=__consumer_offsets-5, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:25,024] INFO [Log partition=__consumer_offsets-5, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:25,025] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-5, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 108ms (47/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:25,028] INFO [Log partition=__consumer_offsets-6, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:25,028] INFO [Log partition=__consumer_offsets-6, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:25,138] INFO [Log partition=__consumer_offsets-6, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:25,139] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-6, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 113ms (48/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:25,142] INFO [Log partition=__consumer_offsets-7, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:25,142] INFO [Log partition=__consumer_offsets-7, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:25,247] INFO [Log partition=__consumer_offsets-7, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:25,248] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-7, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 108ms (49/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:25,251] INFO [Log partition=__consumer_offsets-8, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:25,251] INFO [Log partition=__consumer_offsets-8, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:25,357] INFO [Log partition=__consumer_offsets-8, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:25,359] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-8, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 110ms (50/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:25,361] INFO [Log partition=__consumer_offsets-9, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:08:25,361] INFO [Log partition=__consumer_offsets-9, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:25,468] INFO [Log partition=__consumer_offsets-9, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:08:25,470] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-9, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 111ms (51/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:08:25,472] INFO Loaded 51 logs in 5914ms. (kafka.log.LogManager)
[2020-12-29 13:08:25,484] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-12-29 13:08:25,484] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-12-29 13:08:25,787] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-12-29 13:08:25,819] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2020-12-29 13:08:25,844] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:08:25,846] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:08:25,846] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:08:25,854] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:08:25,868] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-12-29 13:08:25,912] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-12-29 13:08:25,930] INFO Stat of the created znode at /brokers/ids/0 is: 195,195,1609243705924,1609243705924,1,0,0,72067417741262848,196,0,195
 (kafka.zk.KafkaZkClient)
[2020-12-29 13:08:25,931] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://192.168.0.230:9092, czxid (broker epoch): 195 (kafka.zk.KafkaZkClient)
[2020-12-29 13:08:25,997] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:08:26,004] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:08:26,005] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:08:26,035] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:08:26,036] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:08:26,041] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,055] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2020-12-29 13:08:26,078] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-12-29 13:08:26,081] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-12-29 13:08:26,081] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-12-29 13:08:26,124] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:08:26,153] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-12-29 13:08:26,157] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2020-12-29 13:08:26,165] INFO Processing override for entityPath: topics/travelportal.readers with config: HashMap() (kafka.server.DynamicConfigManager)
[2020-12-29 13:08:26,177] INFO Processing override for entityPath: topics/travelportal.readers with config: HashMap() (kafka.server.DynamicConfigManager)
[2020-12-29 13:08:26,190] INFO [SocketServer brokerId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2020-12-29 13:08:26,197] INFO [SocketServer brokerId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2020-12-29 13:08:26,198] INFO [SocketServer brokerId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2020-12-29 13:08:26,207] INFO Kafka version: 2.6.0 (org.apache.kafka.common.utils.AppInfoParser)
[2020-12-29 13:08:26,207] INFO Kafka commitId: 62abe01bee039651 (org.apache.kafka.common.utils.AppInfoParser)
[2020-12-29 13:08:26,208] INFO Kafka startTimeMs: 1609243706199 (org.apache.kafka.common.utils.AppInfoParser)
[2020-12-29 13:08:26,212] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-12-29 13:08:26,274] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, travelportal.readers-0, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-12-29 13:08:26,289] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,299] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,303] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,306] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,309] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,313] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,322] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,325] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,327] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,330] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,334] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,340] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,343] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,347] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,350] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,354] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,358] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,361] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,367] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,371] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,376] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,380] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,384] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,388] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,391] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 2 (kafka.cluster.Partition)
[2020-12-29 13:08:26,392] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,396] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,405] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,408] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,412] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,416] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,419] INFO [Partition travelportal.readers-0 broker=0] Log loaded for partition travelportal.readers-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,423] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 2 (kafka.cluster.Partition)
[2020-12-29 13:08:26,423] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,426] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,429] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,433] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,436] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,438] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,441] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,444] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,446] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,449] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,456] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,459] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,462] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,465] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,468] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,472] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,474] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,477] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:08:26,484] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,486] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,487] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,490] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 4 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,494] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,497] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 11 milliseconds, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,502] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,503] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 9 milliseconds, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,503] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,504] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 2 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,507] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,508] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 4 milliseconds, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,510] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,511] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,511] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,512] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 3 milliseconds, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,517] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,520] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 9 milliseconds, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,521] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,521] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 4 milliseconds, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,522] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,522] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,523] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,523] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 1 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,524] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,524] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,525] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,525] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 1 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,526] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,527] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,526] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,528] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,535] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 9 milliseconds, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,535] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,536] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 9 milliseconds, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,537] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,537] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 10 milliseconds, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,538] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,539] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,538] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 3 milliseconds, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,539] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,540] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 3 milliseconds, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,540] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,541] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 3 milliseconds, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,541] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,542] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,542] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 3 milliseconds, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,543] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,545] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 6 milliseconds, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,551] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,551] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 11 milliseconds, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,552] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,552] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,553] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,553] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,552] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 11 milliseconds, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,555] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,557] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,557] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,558] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,558] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,558] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,559] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,559] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,560] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,560] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,561] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,561] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,567] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,570] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,571] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,572] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,572] INFO Static member MemberMetadata(memberId=consumer-travelportal.readers.bonusgroup-2-667a52cd-0a3e-4be5-b4cd-49f8e7a6a900, groupInstanceId=Some(null), clientId=consumer-travelportal.readers.bonusgroup-2, clientHost=/192.168.0.230, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ).groupInstanceId of group travelportal.readers.bonusgroup loaded with member id consumer-travelportal.readers.bonusgroup-2-667a52cd-0a3e-4be5-b4cd-49f8e7a6a900 at generation 1. (kafka.coordinator.group.GroupMetadata$)
[2020-12-29 13:08:26,572] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,573] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,574] INFO Static member MemberMetadata(memberId=consumer-travelportal.readers.bonusgroup-2-667a52cd-0a3e-4be5-b4cd-49f8e7a6a900, groupInstanceId=Some(null), clientId=consumer-travelportal.readers.bonusgroup-2, clientHost=/192.168.0.230, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ).groupInstanceId of group travelportal.readers.bonusgroup loaded with member id consumer-travelportal.readers.bonusgroup-2-667a52cd-0a3e-4be5-b4cd-49f8e7a6a900 at generation 2. (kafka.coordinator.group.GroupMetadata$)
[2020-12-29 13:08:26,576] INFO [GroupCoordinator 0]: Loading group metadata for travelportal.readers.bonusgroup with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:08:26,581] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 39 milliseconds, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,582] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 39 milliseconds, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,582] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 31 milliseconds, of which 31 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,585] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 34 milliseconds, of which 33 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,585] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 33 milliseconds, of which 33 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,586] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 33 milliseconds, of which 33 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,586] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 33 milliseconds, of which 33 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,590] INFO Static member MemberMetadata(memberId=consumer-travelportal.readers.statgroup-2-bd6cd563-b3d4-4679-9818-cb582e98096a, groupInstanceId=Some(null), clientId=consumer-travelportal.readers.statgroup-2, clientHost=/192.168.0.230, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ).groupInstanceId of group travelportal.readers.statgroup loaded with member id consumer-travelportal.readers.statgroup-2-bd6cd563-b3d4-4679-9818-cb582e98096a at generation 1. (kafka.coordinator.group.GroupMetadata$)
[2020-12-29 13:08:26,592] INFO Static member MemberMetadata(memberId=consumer-travelportal.readers.statgroup-2-bd6cd563-b3d4-4679-9818-cb582e98096a, groupInstanceId=Some(null), clientId=consumer-travelportal.readers.statgroup-2, clientHost=/192.168.0.230, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ).groupInstanceId of group travelportal.readers.statgroup loaded with member id consumer-travelportal.readers.statgroup-2-bd6cd563-b3d4-4679-9818-cb582e98096a at generation 2. (kafka.coordinator.group.GroupMetadata$)
[2020-12-29 13:08:26,593] INFO [GroupCoordinator 0]: Loading group metadata for travelportal.readers.statgroup with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:08:26,594] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 39 milliseconds, of which 32 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,594] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 37 milliseconds, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,594] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 37 milliseconds, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,600] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 43 milliseconds, of which 43 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,600] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 42 milliseconds, of which 42 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,601] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 43 milliseconds, of which 43 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,604] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 45 milliseconds, of which 45 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,604] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 45 milliseconds, of which 45 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,605] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 45 milliseconds, of which 45 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,605] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 45 milliseconds, of which 45 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,606] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 45 milliseconds, of which 45 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,606] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 45 milliseconds, of which 45 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,607] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 40 milliseconds, of which 40 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,607] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 37 milliseconds, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,608] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 37 milliseconds, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,608] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 36 milliseconds, of which 36 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,608] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 36 milliseconds, of which 36 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,609] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 36 milliseconds, of which 36 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:26,609] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 36 milliseconds, of which 36 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:08:36,584] INFO [GroupCoordinator 0]: Member consumer-travelportal.readers.bonusgroup-2-667a52cd-0a3e-4be5-b4cd-49f8e7a6a900 in group travelportal.readers.bonusgroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:08:36,586] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.bonusgroup in state PreparingRebalance with old generation 2 (__consumer_offsets-32) (reason: removing member consumer-travelportal.readers.bonusgroup-2-667a52cd-0a3e-4be5-b4cd-49f8e7a6a900 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:08:36,587] INFO [GroupCoordinator 0]: Group travelportal.readers.bonusgroup with generation 3 is now empty (__consumer_offsets-32) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:08:36,615] INFO [GroupCoordinator 0]: Member consumer-travelportal.readers.statgroup-2-bd6cd563-b3d4-4679-9818-cb582e98096a in group travelportal.readers.statgroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:08:36,616] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.statgroup in state PreparingRebalance with old generation 2 (__consumer_offsets-23) (reason: removing member consumer-travelportal.readers.statgroup-2-bd6cd563-b3d4-4679-9818-cb582e98096a on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:08:36,616] INFO [GroupCoordinator 0]: Group travelportal.readers.statgroup with generation 3 is now empty (__consumer_offsets-23) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:40:14,172] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-12-29 13:40:14,173] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-12-29 13:40:14,173] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-12-29 13:40:14,173] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-12-29 13:40:14,178] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-12-29 13:40:14,200] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-12-29 13:40:14,204] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-12-29 13:40:14,244] INFO Server environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:40:14,244] INFO Server environment:host.name=192.168.0.230 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:40:14,244] INFO Server environment:java.version=11.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:40:14,244] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:40:14,245] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:40:14,245] INFO Server environment:java.class.path=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\activation-1.1.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\argparse4j-0.7.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\audience-annotations-0.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\commons-cli-1.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\commons-lang3-3.8.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-api-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-basic-auth-extension-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-file-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-json-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-mirror-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-mirror-client-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-runtime-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-transforms-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\hk2-api-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\hk2-locator-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\hk2-utils-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-annotations-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-core-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-databind-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.inject-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javassist-3.22.0-CR2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javassist-3.26.0-GA.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javax.servlet-api-3.1.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jaxb-api-2.3.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-client-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-common-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-container-servlet-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-hk2-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-media-jaxb-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-server-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jopt-simple-5.0.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-clients-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-log4j-appender-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-examples-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-scala_2.13-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-test-utils-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-tools-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-javadoc.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-scaladoc.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-sources.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-test-sources.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-test.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\log4j-1.2.17.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\lz4-java-1.7.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\maven-artifact-3.6.3.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\metrics-core-2.2.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-buffer-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-codec-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-common-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-handler-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-resolver-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-transport-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-transport-native-epoll-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-transport-native-unix-common-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\paranamer-2.8.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\plexus-utils-3.2.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\reflections-0.9.12.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\rocksdbjni-5.18.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-collection-compat_2.13-2.1.6.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-java8-compat_2.13-0.9.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-library-2.13.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-reflect-2.13.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\slf4j-api-1.7.30.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\snappy-java-1.1.7.3.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\validation-api-2.0.1.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\zookeeper-3.5.8.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\zookeeper-jute-3.5.8.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:40:14,248] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.2\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\development\version control\Git\cmd;D:\Software\posgres\pg11\bin;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\Gpg4win\..\GnuPG\bin;C:\Program Files\PuTTY\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.2\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\Daglemino\AppData\Local\Microsoft\WindowsApps;C:\tools\cuda\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\include;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\extra\CUPTI\libx;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:40:14,249] INFO Server environment:java.io.tmpdir=C:\Users\DAGLEM~1\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:40:14,249] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:40:14,250] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:40:14,250] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:40:14,250] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:40:14,251] INFO Server environment:user.name=Daglemino (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:40:14,251] INFO Server environment:user.home=C:\Users\Daglemino (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:40:14,252] INFO Server environment:user.dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:40:14,252] INFO Server environment:os.memory.free=493MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:40:14,260] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:40:14,260] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:40:14,262] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:40:14,263] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:40:14,264] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir data\zookeeper\version-2 snapdir data\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:40:14,280] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-12-29 13:40:14,284] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 24 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-12-29 13:40:14,288] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-12-29 13:40:14,307] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-12-29 13:40:14,322] INFO Reading snapshot data\zookeeper\version-2\snapshot.b3 (org.apache.zookeeper.server.persistence.FileSnap)
[2020-12-29 13:40:14,362] INFO Snapshotting: 0xc8 to data\zookeeper\version-2\snapshot.c8 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-12-29 13:40:14,404] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-12-29 13:40:18,747] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-12-29 13:40:19,105] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-12-29 13:40:19,175] INFO starting (kafka.server.KafkaServer)
[2020-12-29 13:40:19,177] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-12-29 13:40:19,195] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-12-29 13:40:19,223] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:19,223] INFO Client environment:host.name=192.168.0.230 (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:19,224] INFO Client environment:java.version=11.0.2 (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:19,224] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:19,224] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.2 (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:19,224] INFO Client environment:java.class.path=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\activation-1.1.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\argparse4j-0.7.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\audience-annotations-0.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\commons-cli-1.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\commons-lang3-3.8.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-api-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-basic-auth-extension-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-file-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-json-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-mirror-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-mirror-client-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-runtime-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-transforms-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\hk2-api-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\hk2-locator-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\hk2-utils-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-annotations-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-core-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-databind-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.inject-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javassist-3.22.0-CR2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javassist-3.26.0-GA.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javax.servlet-api-3.1.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jaxb-api-2.3.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-client-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-common-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-container-servlet-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-hk2-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-media-jaxb-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-server-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jopt-simple-5.0.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-clients-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-log4j-appender-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-examples-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-scala_2.13-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-test-utils-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-tools-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-javadoc.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-scaladoc.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-sources.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-test-sources.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-test.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\log4j-1.2.17.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\lz4-java-1.7.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\maven-artifact-3.6.3.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\metrics-core-2.2.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-buffer-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-codec-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-common-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-handler-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-resolver-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-transport-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-transport-native-epoll-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-transport-native-unix-common-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\paranamer-2.8.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\plexus-utils-3.2.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\reflections-0.9.12.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\rocksdbjni-5.18.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-collection-compat_2.13-2.1.6.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-java8-compat_2.13-0.9.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-library-2.13.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-reflect-2.13.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\slf4j-api-1.7.30.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\snappy-java-1.1.7.3.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\validation-api-2.0.1.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\zookeeper-3.5.8.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\zookeeper-jute-3.5.8.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:19,229] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.2\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\development\version control\Git\cmd;D:\Software\posgres\pg11\bin;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\Gpg4win\..\GnuPG\bin;C:\Program Files\PuTTY\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.2\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\Daglemino\AppData\Local\Microsoft\WindowsApps;C:\tools\cuda\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\include;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\extra\CUPTI\libx;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:19,230] INFO Client environment:java.io.tmpdir=C:\Users\DAGLEM~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:19,230] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:19,231] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:19,240] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:19,244] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:19,245] INFO Client environment:user.name=Daglemino (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:19,246] INFO Client environment:user.home=C:\Users\Daglemino (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:19,246] INFO Client environment:user.dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:19,247] INFO Client environment:os.memory.free=1013MB (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:19,255] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:19,257] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:19,260] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@55322aab (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:19,277] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-12-29 13:40:19,284] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-12-29 13:40:19,287] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-12-29 13:40:19,299] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-12-29 13:40:19,303] INFO Socket connection established, initiating session, client: /127.0.0.1:58732, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-12-29 13:40:19,318] INFO Creating new log file: log.c9 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-12-29 13:40:19,331] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100090cb4eb0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2020-12-29 13:40:19,335] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-12-29 13:40:19,591] INFO Cluster ID = faeabPsTRvy-g5J7XJiYXg (kafka.server.KafkaServer)
[2020-12-29 13:40:19,660] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.6-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = data\kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.6-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-12-29 13:40:19,675] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.6-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = data\kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.6-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-12-29 13:40:19,721] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-12-29 13:40:19,721] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-12-29 13:40:19,724] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-12-29 13:40:19,774] INFO Loading logs from log dirs ArraySeq(D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:19,778] INFO Attempting recovery for all logs in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka since no clean shutdown file was found (kafka.log.LogManager)
[2020-12-29 13:40:19,841] INFO [Log partition=travelportal.readers-0, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:19,842] INFO [Log partition=travelportal.readers-0, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:19,891] INFO [Log partition=travelportal.readers-0, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:19,908] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\travelportal.readers-0, topic=travelportal.readers, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 114ms (1/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:19,911] INFO [Log partition=__consumer_offsets-0, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:19,911] INFO [Log partition=__consumer_offsets-0, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:19,922] INFO [Log partition=__consumer_offsets-0, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:19,928] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-0, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (2/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:19,932] INFO [Log partition=__consumer_offsets-1, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:19,933] INFO [Log partition=__consumer_offsets-1, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:19,949] INFO [Log partition=__consumer_offsets-1, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:19,953] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-1, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (3/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:19,956] INFO [Log partition=__consumer_offsets-10, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:19,956] INFO [Log partition=__consumer_offsets-10, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:19,967] INFO [Log partition=__consumer_offsets-10, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:19,972] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-10, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (4/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:19,974] INFO [Log partition=__consumer_offsets-11, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:19,975] INFO [Log partition=__consumer_offsets-11, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:19,986] INFO [Log partition=__consumer_offsets-11, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:19,991] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-11, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (5/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:19,993] INFO [Log partition=__consumer_offsets-12, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:19,993] INFO [Log partition=__consumer_offsets-12, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,003] INFO [Log partition=__consumer_offsets-12, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,007] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-12, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (6/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,009] INFO [Log partition=__consumer_offsets-13, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,010] INFO [Log partition=__consumer_offsets-13, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,020] INFO [Log partition=__consumer_offsets-13, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,025] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-13, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (7/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,027] INFO [Log partition=__consumer_offsets-14, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,027] INFO [Log partition=__consumer_offsets-14, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,038] INFO [Log partition=__consumer_offsets-14, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,042] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-14, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (8/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,045] INFO [Log partition=__consumer_offsets-15, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,045] INFO [Log partition=__consumer_offsets-15, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,057] INFO [Log partition=__consumer_offsets-15, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,061] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-15, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (9/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,065] INFO [Log partition=__consumer_offsets-16, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,066] INFO [Log partition=__consumer_offsets-16, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,075] INFO [Log partition=__consumer_offsets-16, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,079] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-16, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (10/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,082] INFO [Log partition=__consumer_offsets-17, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,082] INFO [Log partition=__consumer_offsets-17, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,091] INFO [Log partition=__consumer_offsets-17, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,093] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-17, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (11/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,096] INFO [Log partition=__consumer_offsets-18, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,096] INFO [Log partition=__consumer_offsets-18, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,105] INFO [Log partition=__consumer_offsets-18, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,111] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-18, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (12/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,113] INFO [Log partition=__consumer_offsets-19, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,115] INFO [Log partition=__consumer_offsets-19, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,126] INFO [Log partition=__consumer_offsets-19, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,130] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-19, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (13/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,133] INFO [Log partition=__consumer_offsets-2, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,134] INFO [Log partition=__consumer_offsets-2, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,144] INFO [Log partition=__consumer_offsets-2, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,149] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-2, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (14/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,151] INFO [Log partition=__consumer_offsets-20, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,151] INFO [Log partition=__consumer_offsets-20, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,180] INFO [Log partition=__consumer_offsets-20, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,185] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-20, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 35ms (15/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,188] INFO [Log partition=__consumer_offsets-21, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,189] INFO [Log partition=__consumer_offsets-21, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,200] INFO [Log partition=__consumer_offsets-21, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,203] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-21, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (16/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,206] INFO [Log partition=__consumer_offsets-22, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,207] INFO [Log partition=__consumer_offsets-22, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,215] INFO [Log partition=__consumer_offsets-22, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,219] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-22, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (17/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,222] INFO [Log partition=__consumer_offsets-23, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,223] INFO [Log partition=__consumer_offsets-23, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,249] INFO [ProducerStateManager partition=__consumer_offsets-23] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-12-29 13:40:20,273] INFO [Log partition=__consumer_offsets-23, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,275] INFO [ProducerStateManager partition=__consumer_offsets-23] Loading producer state from snapshot file 'D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-23\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-12-29 13:40:20,283] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-23, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 63ms (18/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,286] INFO [Log partition=__consumer_offsets-24, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,286] INFO [Log partition=__consumer_offsets-24, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,309] INFO [Log partition=__consumer_offsets-24, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,311] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-24, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 28ms (19/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,315] INFO [Log partition=__consumer_offsets-25, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,315] INFO [Log partition=__consumer_offsets-25, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,327] INFO [Log partition=__consumer_offsets-25, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,331] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-25, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (20/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,334] INFO [Log partition=__consumer_offsets-26, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,336] INFO [Log partition=__consumer_offsets-26, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,345] INFO [Log partition=__consumer_offsets-26, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,350] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-26, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (21/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,352] INFO [Log partition=__consumer_offsets-27, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,353] INFO [Log partition=__consumer_offsets-27, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,366] INFO [Log partition=__consumer_offsets-27, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,370] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-27, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (22/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,372] INFO [Log partition=__consumer_offsets-28, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,375] INFO [Log partition=__consumer_offsets-28, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,385] INFO [Log partition=__consumer_offsets-28, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,388] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-28, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (23/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,390] INFO [Log partition=__consumer_offsets-29, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,390] INFO [Log partition=__consumer_offsets-29, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,399] INFO [Log partition=__consumer_offsets-29, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,401] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-29, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (24/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,404] INFO [Log partition=__consumer_offsets-3, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,406] INFO [Log partition=__consumer_offsets-3, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,415] INFO [Log partition=__consumer_offsets-3, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,418] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-3, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (25/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,421] INFO [Log partition=__consumer_offsets-30, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,423] INFO [Log partition=__consumer_offsets-30, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,433] INFO [Log partition=__consumer_offsets-30, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,435] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-30, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (26/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,438] INFO [Log partition=__consumer_offsets-31, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,438] INFO [Log partition=__consumer_offsets-31, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,449] INFO [Log partition=__consumer_offsets-31, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,451] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-31, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (27/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,454] INFO [Log partition=__consumer_offsets-32, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,456] INFO [Log partition=__consumer_offsets-32, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,466] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-12-29 13:40:20,478] INFO [Log partition=__consumer_offsets-32, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,479] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file 'D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-32\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-12-29 13:40:20,484] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-32, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 33ms (28/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,487] INFO [Log partition=__consumer_offsets-33, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,490] INFO [Log partition=__consumer_offsets-33, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,499] INFO [Log partition=__consumer_offsets-33, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,501] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-33, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (29/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,503] INFO [Log partition=__consumer_offsets-34, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,505] INFO [Log partition=__consumer_offsets-34, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,514] INFO [Log partition=__consumer_offsets-34, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,516] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-34, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (30/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,519] INFO [Log partition=__consumer_offsets-35, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,520] INFO [Log partition=__consumer_offsets-35, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,533] INFO [Log partition=__consumer_offsets-35, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,535] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-35, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (31/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,538] INFO [Log partition=__consumer_offsets-36, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,539] INFO [Log partition=__consumer_offsets-36, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,549] INFO [Log partition=__consumer_offsets-36, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,551] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-36, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (32/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,554] INFO [Log partition=__consumer_offsets-37, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,555] INFO [Log partition=__consumer_offsets-37, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,567] INFO [Log partition=__consumer_offsets-37, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,570] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-37, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (33/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,575] INFO [Log partition=__consumer_offsets-38, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,576] INFO [Log partition=__consumer_offsets-38, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,586] INFO [Log partition=__consumer_offsets-38, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,588] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-38, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (34/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,591] INFO [Log partition=__consumer_offsets-39, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,591] INFO [Log partition=__consumer_offsets-39, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,601] INFO [Log partition=__consumer_offsets-39, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,604] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-39, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (35/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,606] INFO [Log partition=__consumer_offsets-4, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,607] INFO [Log partition=__consumer_offsets-4, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,620] INFO [Log partition=__consumer_offsets-4, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,623] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-4, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (36/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,625] INFO [Log partition=__consumer_offsets-40, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,625] INFO [Log partition=__consumer_offsets-40, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,635] INFO [Log partition=__consumer_offsets-40, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,638] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-40, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (37/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,640] INFO [Log partition=__consumer_offsets-41, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,641] INFO [Log partition=__consumer_offsets-41, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,650] INFO [Log partition=__consumer_offsets-41, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,659] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-41, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (38/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,661] INFO [Log partition=__consumer_offsets-42, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,661] INFO [Log partition=__consumer_offsets-42, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,672] INFO [Log partition=__consumer_offsets-42, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,675] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-42, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (39/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,678] INFO [Log partition=__consumer_offsets-43, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,679] INFO [Log partition=__consumer_offsets-43, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,689] INFO [Log partition=__consumer_offsets-43, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,691] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-43, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (40/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,693] INFO [Log partition=__consumer_offsets-44, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,694] INFO [Log partition=__consumer_offsets-44, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,704] INFO [Log partition=__consumer_offsets-44, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,708] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-44, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (41/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,710] INFO [Log partition=__consumer_offsets-45, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,711] INFO [Log partition=__consumer_offsets-45, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,720] INFO [Log partition=__consumer_offsets-45, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,723] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-45, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (42/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,726] INFO [Log partition=__consumer_offsets-46, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,726] INFO [Log partition=__consumer_offsets-46, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,738] INFO [Log partition=__consumer_offsets-46, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,740] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-46, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (43/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,742] INFO [Log partition=__consumer_offsets-47, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,743] INFO [Log partition=__consumer_offsets-47, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,752] INFO [Log partition=__consumer_offsets-47, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,754] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-47, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (44/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,756] INFO [Log partition=__consumer_offsets-48, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,756] INFO [Log partition=__consumer_offsets-48, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,765] INFO [Log partition=__consumer_offsets-48, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,767] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-48, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (45/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,769] INFO [Log partition=__consumer_offsets-49, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,773] INFO [Log partition=__consumer_offsets-49, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,781] INFO [Log partition=__consumer_offsets-49, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,782] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-49, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (46/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,784] INFO [Log partition=__consumer_offsets-5, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,785] INFO [Log partition=__consumer_offsets-5, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,798] INFO [Log partition=__consumer_offsets-5, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,800] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-5, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (47/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,802] INFO [Log partition=__consumer_offsets-6, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,805] INFO [Log partition=__consumer_offsets-6, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,815] INFO [Log partition=__consumer_offsets-6, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,817] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-6, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (48/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,819] INFO [Log partition=__consumer_offsets-7, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,822] INFO [Log partition=__consumer_offsets-7, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,833] INFO [Log partition=__consumer_offsets-7, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,835] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-7, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (49/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,842] INFO [Log partition=__consumer_offsets-8, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,842] INFO [Log partition=__consumer_offsets-8, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,852] INFO [Log partition=__consumer_offsets-8, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,854] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-8, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (50/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,856] INFO [Log partition=__consumer_offsets-9, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 13:40:20,856] INFO [Log partition=__consumer_offsets-9, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,864] INFO [Log partition=__consumer_offsets-9, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:20,866] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-9, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (51/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:20,869] INFO Loaded 51 logs in 1094ms. (kafka.log.LogManager)
[2020-12-29 13:40:20,885] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-12-29 13:40:20,886] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-12-29 13:40:21,284] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-12-29 13:40:21,326] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2020-12-29 13:40:21,346] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:40:21,349] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:40:21,349] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:40:21,349] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:40:21,367] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-12-29 13:40:21,440] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-12-29 13:40:21,472] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '72067417741262848' does not match current session '72067544217485312' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2020-12-29 13:40:21,481] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1821)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1759)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1726)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:95)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:293)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:44)
	at kafka.Kafka$.main(Kafka.scala:82)
	at kafka.Kafka.main(Kafka.scala)
[2020-12-29 13:40:21,485] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2020-12-29 13:40:21,488] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2020-12-29 13:40:21,496] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2020-12-29 13:40:21,503] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2020-12-29 13:40:21,504] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-12-29 13:40:21,506] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-12-29 13:40:21,506] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-12-29 13:40:21,508] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2020-12-29 13:40:21,510] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2020-12-29 13:40:21,511] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2020-12-29 13:40:21,512] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2020-12-29 13:40:21,515] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:40:21,560] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:40:21,560] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:40:21,561] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:40:21,747] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:40:21,747] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:40:21,748] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:40:21,951] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:40:21,951] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:40:21,952] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:40:21,958] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:40:21,958] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:40:21,964] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2020-12-29 13:40:21,965] INFO Shutting down. (kafka.log.LogManager)
[2020-12-29 13:40:27,743] INFO Shutdown complete. (kafka.log.LogManager)
[2020-12-29 13:40:27,744] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-12-29 13:40:27,848] INFO Session: 0x100090cb4eb0000 closed (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:27,849] INFO EventThread shut down for session: 0x100090cb4eb0000 (org.apache.zookeeper.ClientCnxn)
[2020-12-29 13:40:27,850] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-12-29 13:40:27,850] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-12-29 13:40:28,726] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-12-29 13:40:28,726] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-12-29 13:40:28,730] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-12-29 13:40:29,729] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-12-29 13:40:29,729] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-12-29 13:40:29,730] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-12-29 13:40:30,728] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-12-29 13:40:30,728] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-12-29 13:40:30,731] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2020-12-29 13:40:30,754] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2020-12-29 13:40:30,762] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2020-12-29 13:40:30,762] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2020-12-29 13:40:30,768] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2020-12-29 13:40:34,682] INFO Expiring session 0x10008ef42590000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 13:40:39,674] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-12-29 13:40:39,989] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-12-29 13:40:40,056] INFO starting (kafka.server.KafkaServer)
[2020-12-29 13:40:40,058] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-12-29 13:40:40,078] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-12-29 13:40:40,102] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:40,102] INFO Client environment:host.name=192.168.0.230 (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:40,103] INFO Client environment:java.version=11.0.2 (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:40,103] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:40,103] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.2 (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:40,103] INFO Client environment:java.class.path=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\activation-1.1.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\argparse4j-0.7.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\audience-annotations-0.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\commons-cli-1.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\commons-lang3-3.8.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-api-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-basic-auth-extension-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-file-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-json-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-mirror-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-mirror-client-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-runtime-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-transforms-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\hk2-api-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\hk2-locator-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\hk2-utils-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-annotations-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-core-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-databind-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.inject-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javassist-3.22.0-CR2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javassist-3.26.0-GA.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javax.servlet-api-3.1.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jaxb-api-2.3.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-client-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-common-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-container-servlet-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-hk2-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-media-jaxb-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-server-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jopt-simple-5.0.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-clients-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-log4j-appender-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-examples-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-scala_2.13-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-test-utils-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-tools-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-javadoc.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-scaladoc.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-sources.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-test-sources.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-test.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\log4j-1.2.17.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\lz4-java-1.7.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\maven-artifact-3.6.3.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\metrics-core-2.2.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-buffer-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-codec-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-common-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-handler-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-resolver-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-transport-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-transport-native-epoll-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-transport-native-unix-common-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\paranamer-2.8.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\plexus-utils-3.2.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\reflections-0.9.12.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\rocksdbjni-5.18.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-collection-compat_2.13-2.1.6.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-java8-compat_2.13-0.9.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-library-2.13.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-reflect-2.13.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\slf4j-api-1.7.30.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\snappy-java-1.1.7.3.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\validation-api-2.0.1.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\zookeeper-3.5.8.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\zookeeper-jute-3.5.8.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:40,106] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.2\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\development\version control\Git\cmd;D:\Software\posgres\pg11\bin;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\Gpg4win\..\GnuPG\bin;C:\Program Files\PuTTY\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.2\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\Daglemino\AppData\Local\Microsoft\WindowsApps;C:\tools\cuda\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\include;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\extra\CUPTI\libx;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:40,106] INFO Client environment:java.io.tmpdir=C:\Users\DAGLEM~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:40,107] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:40,108] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:40,108] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:40,108] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:40,109] INFO Client environment:user.name=Daglemino (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:40,110] INFO Client environment:user.home=C:\Users\Daglemino (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:40,117] INFO Client environment:user.dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:40,120] INFO Client environment:os.memory.free=1013MB (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:40,120] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:40,121] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:40,124] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@55322aab (org.apache.zookeeper.ZooKeeper)
[2020-12-29 13:40:40,135] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-12-29 13:40:40,140] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-12-29 13:40:40,144] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-12-29 13:40:40,152] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-12-29 13:40:40,156] INFO Socket connection established, initiating session, client: /127.0.0.1:58763, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-12-29 13:40:40,166] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100090cb4eb0001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2020-12-29 13:40:40,174] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-12-29 13:40:40,414] INFO Cluster ID = faeabPsTRvy-g5J7XJiYXg (kafka.server.KafkaServer)
[2020-12-29 13:40:40,465] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.6-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = data\kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.6-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-12-29 13:40:40,477] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.6-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = data\kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.6-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-12-29 13:40:40,521] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-12-29 13:40:40,522] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-12-29 13:40:40,528] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-12-29 13:40:40,584] INFO Loading logs from log dirs ArraySeq(D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,588] INFO Skipping recovery for all logs in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka since clean shutdown file was found (kafka.log.LogManager)
[2020-12-29 13:40:40,682] INFO [Log partition=travelportal.readers-0, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,704] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\travelportal.readers-0, topic=travelportal.readers, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 89ms (1/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,708] INFO [Log partition=__consumer_offsets-0, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,712] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-0, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (2/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,716] INFO [Log partition=__consumer_offsets-1, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,723] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-1, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (3/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,728] INFO [Log partition=__consumer_offsets-10, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,732] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-10, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,737] INFO [Log partition=__consumer_offsets-11, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,741] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-11, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (5/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,746] INFO [Log partition=__consumer_offsets-12, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,750] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-12, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (6/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,755] INFO [Log partition=__consumer_offsets-13, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,758] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-13, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (7/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,762] INFO [Log partition=__consumer_offsets-14, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,765] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-14, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,770] INFO [Log partition=__consumer_offsets-15, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,773] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-15, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (9/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,778] INFO [Log partition=__consumer_offsets-16, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,780] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-16, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,784] INFO [Log partition=__consumer_offsets-17, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,786] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-17, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (11/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,790] INFO [Log partition=__consumer_offsets-18, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,796] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-18, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (12/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,800] INFO [Log partition=__consumer_offsets-19, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,805] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-19, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (13/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,810] INFO [Log partition=__consumer_offsets-2, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,814] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-2, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (14/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,821] INFO [Log partition=__consumer_offsets-20, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,826] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-20, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (15/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,831] INFO [Log partition=__consumer_offsets-21, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,841] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-21, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (16/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,847] INFO [Log partition=__consumer_offsets-22, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,852] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-22, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (17/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,883] INFO [Log partition=__consumer_offsets-23, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,890] INFO [ProducerStateManager partition=__consumer_offsets-23] Loading producer state from snapshot file 'D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-23\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-12-29 13:40:40,901] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-23, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 49ms (18/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,906] INFO [Log partition=__consumer_offsets-24, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,908] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-24, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (19/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,913] INFO [Log partition=__consumer_offsets-25, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,916] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-25, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (20/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,920] INFO [Log partition=__consumer_offsets-26, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,922] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-26, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (21/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,927] INFO [Log partition=__consumer_offsets-27, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,930] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-27, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (22/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,935] INFO [Log partition=__consumer_offsets-28, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,937] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-28, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (23/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,941] INFO [Log partition=__consumer_offsets-29, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,943] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-29, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (24/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,948] INFO [Log partition=__consumer_offsets-3, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,950] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-3, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (25/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,958] INFO [Log partition=__consumer_offsets-30, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,960] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-30, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (26/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,964] INFO [Log partition=__consumer_offsets-31, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,966] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-31, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (27/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,975] INFO [Log partition=__consumer_offsets-32, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:40,977] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file 'D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-32\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-12-29 13:40:40,989] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-32, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 22ms (28/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:40,998] INFO [Log partition=__consumer_offsets-33, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:41,002] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-33, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (29/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:41,007] INFO [Log partition=__consumer_offsets-34, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:41,014] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-34, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (30/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:41,022] INFO [Log partition=__consumer_offsets-35, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:41,025] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-35, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (31/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:41,030] INFO [Log partition=__consumer_offsets-36, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:41,041] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-36, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (32/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:41,048] INFO [Log partition=__consumer_offsets-37, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:41,050] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-37, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (33/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:41,058] INFO [Log partition=__consumer_offsets-38, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:41,061] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-38, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (34/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:41,065] INFO [Log partition=__consumer_offsets-39, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:41,067] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-39, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (35/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:41,075] INFO [Log partition=__consumer_offsets-4, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:41,078] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-4, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (36/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:41,083] INFO [Log partition=__consumer_offsets-40, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:41,085] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-40, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (37/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:41,106] INFO [Log partition=__consumer_offsets-41, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:41,107] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-41, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (38/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:41,112] INFO [Log partition=__consumer_offsets-42, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:41,114] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-42, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (39/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:41,120] INFO [Log partition=__consumer_offsets-43, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:41,122] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-43, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (40/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:41,128] INFO [Log partition=__consumer_offsets-44, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:41,130] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-44, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (41/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:41,135] INFO [Log partition=__consumer_offsets-45, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:41,139] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-45, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (42/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:41,144] INFO [Log partition=__consumer_offsets-46, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:41,146] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-46, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (43/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:41,152] INFO [Log partition=__consumer_offsets-47, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:41,154] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-47, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (44/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:41,161] INFO [Log partition=__consumer_offsets-48, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:41,164] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-48, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (45/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:41,169] INFO [Log partition=__consumer_offsets-49, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:41,172] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-49, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (46/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:41,176] INFO [Log partition=__consumer_offsets-5, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:41,180] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-5, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (47/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:41,184] INFO [Log partition=__consumer_offsets-6, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:41,186] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-6, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (48/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:41,190] INFO [Log partition=__consumer_offsets-7, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:41,192] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-7, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (49/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:41,197] INFO [Log partition=__consumer_offsets-8, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:41,202] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-8, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (50/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:41,207] INFO [Log partition=__consumer_offsets-9, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 13:40:41,209] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-9, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (51/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 13:40:41,214] INFO Loaded 51 logs in 630ms. (kafka.log.LogManager)
[2020-12-29 13:40:41,235] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-12-29 13:40:41,236] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-12-29 13:40:41,703] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-12-29 13:40:41,762] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2020-12-29 13:40:41,785] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:40:41,788] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:40:41,788] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:40:41,788] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:40:41,805] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-12-29 13:40:41,871] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-12-29 13:40:41,901] INFO Stat of the created znode at /brokers/ids/0 is: 232,232,1609245641890,1609245641890,1,0,0,72067544217485313,196,0,232
 (kafka.zk.KafkaZkClient)
[2020-12-29 13:40:41,903] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://192.168.0.230:9092, czxid (broker epoch): 232 (kafka.zk.KafkaZkClient)
[2020-12-29 13:40:41,985] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:40:41,990] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:40:41,992] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:40:42,037] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:40:42,039] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:40:42,046] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,060] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:3000,blockEndProducerId:3999) by writing to Zk with path version 4 (kafka.coordinator.transaction.ProducerIdManager)
[2020-12-29 13:40:42,102] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-12-29 13:40:42,114] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-12-29 13:40:42,120] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-12-29 13:40:42,161] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 13:40:42,188] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-12-29 13:40:42,216] INFO [SocketServer brokerId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2020-12-29 13:40:42,223] INFO [SocketServer brokerId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2020-12-29 13:40:42,224] INFO [SocketServer brokerId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2020-12-29 13:40:42,235] INFO Kafka version: 2.6.0 (org.apache.kafka.common.utils.AppInfoParser)
[2020-12-29 13:40:42,235] INFO Kafka commitId: 62abe01bee039651 (org.apache.kafka.common.utils.AppInfoParser)
[2020-12-29 13:40:42,236] INFO Kafka startTimeMs: 1609245642225 (org.apache.kafka.common.utils.AppInfoParser)
[2020-12-29 13:40:42,240] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-12-29 13:40:42,340] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, travelportal.readers-0, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-12-29 13:40:42,355] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,389] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,394] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,402] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,407] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,416] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,423] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,429] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,433] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,446] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,451] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,455] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,460] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,465] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,469] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,475] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,480] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,484] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,487] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,495] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,498] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,502] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,507] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,514] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,520] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 3 (kafka.cluster.Partition)
[2020-12-29 13:40:42,521] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,526] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,532] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,536] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,541] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,545] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,551] INFO [Partition travelportal.readers-0 broker=0] Log loaded for partition travelportal.readers-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,556] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 3 (kafka.cluster.Partition)
[2020-12-29 13:40:42,557] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,562] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,574] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,579] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,583] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,588] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,592] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,598] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,603] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,606] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,611] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,616] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,620] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,625] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,630] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,641] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,652] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,656] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 13:40:42,670] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,672] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,673] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,674] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,677] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,678] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,680] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 9 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,684] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,705] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 32 milliseconds, of which 32 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,711] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 37 milliseconds, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,707] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,712] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 35 milliseconds, of which 35 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,719] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,722] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 44 milliseconds, of which 43 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,724] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,726] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 42 milliseconds, of which 42 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,727] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,738] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 31 milliseconds, of which 31 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,742] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,747] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 28 milliseconds, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,749] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,751] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 27 milliseconds, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,753] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,754] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 27 milliseconds, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,754] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,756] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 15 milliseconds, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,757] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,758] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 9 milliseconds, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,759] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 6 milliseconds, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,764] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,771] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 17 milliseconds, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,771] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,773] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 16 milliseconds, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,775] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,778] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 20 milliseconds, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,779] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,786] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 23 milliseconds, of which 23 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,789] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,791] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 20 milliseconds, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,793] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 18 milliseconds, of which 18 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,793] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,794] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 15 milliseconds, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,801] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,804] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 15 milliseconds, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,806] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,807] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 15 milliseconds, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,808] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,809] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 15 milliseconds, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,809] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,810] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 9 milliseconds, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,811] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,823] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,829] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,830] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,831] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,834] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,836] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,837] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,837] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,838] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,839] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,839] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,840] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,841] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,844] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,849] INFO Static member MemberMetadata(memberId=consumer-travelportal.readers.bonusgroup-2-667a52cd-0a3e-4be5-b4cd-49f8e7a6a900, groupInstanceId=Some(null), clientId=consumer-travelportal.readers.bonusgroup-2, clientHost=/192.168.0.230, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ).groupInstanceId of group travelportal.readers.bonusgroup loaded with member id consumer-travelportal.readers.bonusgroup-2-667a52cd-0a3e-4be5-b4cd-49f8e7a6a900 at generation 1. (kafka.coordinator.group.GroupMetadata$)
[2020-12-29 13:40:42,850] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,852] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,854] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,854] INFO Static member MemberMetadata(memberId=consumer-travelportal.readers.bonusgroup-2-667a52cd-0a3e-4be5-b4cd-49f8e7a6a900, groupInstanceId=Some(null), clientId=consumer-travelportal.readers.bonusgroup-2, clientHost=/192.168.0.230, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ).groupInstanceId of group travelportal.readers.bonusgroup loaded with member id consumer-travelportal.readers.bonusgroup-2-667a52cd-0a3e-4be5-b4cd-49f8e7a6a900 at generation 2. (kafka.coordinator.group.GroupMetadata$)
[2020-12-29 13:40:42,855] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,858] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,859] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,860] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,861] INFO [GroupCoordinator 0]: Loading group metadata for travelportal.readers.bonusgroup with generation 3 (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:40:42,869] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 62 milliseconds, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,873] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 66 milliseconds, of which 66 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,874] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 65 milliseconds, of which 65 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,875] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 64 milliseconds, of which 64 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,879] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 56 milliseconds, of which 56 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,880] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 52 milliseconds, of which 51 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,884] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 55 milliseconds, of which 55 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,891] INFO Static member MemberMetadata(memberId=consumer-travelportal.readers.statgroup-2-bd6cd563-b3d4-4679-9818-cb582e98096a, groupInstanceId=Some(null), clientId=consumer-travelportal.readers.statgroup-2, clientHost=/192.168.0.230, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ).groupInstanceId of group travelportal.readers.statgroup loaded with member id consumer-travelportal.readers.statgroup-2-bd6cd563-b3d4-4679-9818-cb582e98096a at generation 1. (kafka.coordinator.group.GroupMetadata$)
[2020-12-29 13:40:42,892] INFO Static member MemberMetadata(memberId=consumer-travelportal.readers.statgroup-2-bd6cd563-b3d4-4679-9818-cb582e98096a, groupInstanceId=Some(null), clientId=consumer-travelportal.readers.statgroup-2, clientHost=/192.168.0.230, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ).groupInstanceId of group travelportal.readers.statgroup loaded with member id consumer-travelportal.readers.statgroup-2-bd6cd563-b3d4-4679-9818-cb582e98096a at generation 2. (kafka.coordinator.group.GroupMetadata$)
[2020-12-29 13:40:42,893] INFO [GroupCoordinator 0]: Loading group metadata for travelportal.readers.statgroup with generation 3 (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:40:42,893] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 62 milliseconds, of which 56 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,895] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 62 milliseconds, of which 61 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,903] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 67 milliseconds, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,903] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 66 milliseconds, of which 66 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,905] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 68 milliseconds, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,905] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 67 milliseconds, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,906] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 67 milliseconds, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,907] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 68 milliseconds, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,907] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 67 milliseconds, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,908] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 67 milliseconds, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,909] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 65 milliseconds, of which 65 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,910] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 60 milliseconds, of which 60 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,911] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 59 milliseconds, of which 58 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,918] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 64 milliseconds, of which 64 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,919] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 64 milliseconds, of which 63 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,920] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 62 milliseconds, of which 61 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,920] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 61 milliseconds, of which 61 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,921] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 61 milliseconds, of which 61 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:40:42,922] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 62 milliseconds, of which 61 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:41:12,445] INFO [Admin Manager on Broker 0]: Updating topic travelportal.readers with new configuration kafka.server.KafkaConfig@6f4e076a (kafka.server.AdminManager)
[2020-12-29 13:41:12,464] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2020-12-29 13:41:12,470] INFO Processing override for entityPath: topics/travelportal.readers with config: HashMap() (kafka.server.DynamicConfigManager)
[2020-12-29 13:41:12,516] INFO [Admin Manager on Broker 0]: Updating topic travelportal.readers with new configuration kafka.server.KafkaConfig@6f4e076a (kafka.server.AdminManager)
[2020-12-29 13:41:12,530] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2020-12-29 13:41:12,534] INFO Processing override for entityPath: topics/travelportal.readers with config: HashMap() (kafka.server.DynamicConfigManager)
[2020-12-29 13:41:12,672] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.bonusgroup in state PreparingRebalance with old generation 3 (__consumer_offsets-32) (reason: Adding new member consumer-travelportal.readers.bonusgroup-2-2144474b-3fde-4fe1-92bc-4a2404fba6f8 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:41:12,684] INFO [GroupCoordinator 0]: Stabilized group travelportal.readers.bonusgroup generation 4 (__consumer_offsets-32) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:41:12,708] INFO [GroupCoordinator 0]: Assignment received from leader for group travelportal.readers.bonusgroup for generation 4 (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:42:15,075] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-61094 in state PreparingRebalance with old generation 0 (__consumer_offsets-41) (reason: Adding new member consumer-console-consumer-61094-1-de1618b4-9a92-40f3-90d5-1642bb8c6f48 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:42:15,076] INFO [GroupCoordinator 0]: Stabilized group console-consumer-61094 generation 1 (__consumer_offsets-41) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:42:15,080] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-61094 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:43:31,991] INFO [GroupCoordinator 0]: Member consumer-travelportal.readers.bonusgroup-2-2144474b-3fde-4fe1-92bc-4a2404fba6f8 in group travelportal.readers.bonusgroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:43:31,991] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.bonusgroup in state PreparingRebalance with old generation 4 (__consumer_offsets-32) (reason: removing member consumer-travelportal.readers.bonusgroup-2-2144474b-3fde-4fe1-92bc-4a2404fba6f8 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:43:31,995] INFO [GroupCoordinator 0]: Group travelportal.readers.bonusgroup with generation 5 is now empty (__consumer_offsets-32) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:43:49,175] INFO [Admin Manager on Broker 0]: Updating topic travelportal.readers with new configuration kafka.server.KafkaConfig@6f4e076a (kafka.server.AdminManager)
[2020-12-29 13:43:49,185] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2020-12-29 13:43:49,189] INFO Processing override for entityPath: topics/travelportal.readers with config: HashMap() (kafka.server.DynamicConfigManager)
[2020-12-29 13:43:49,331] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.bonusgroup in state PreparingRebalance with old generation 5 (__consumer_offsets-32) (reason: Adding new member consumer-travelportal.readers.bonusgroup-2-e6e214c4-9b76-44b8-a489-33a696b042f0 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:43:49,332] INFO [GroupCoordinator 0]: Stabilized group travelportal.readers.bonusgroup generation 6 (__consumer_offsets-32) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:43:49,342] INFO [GroupCoordinator 0]: Assignment received from leader for group travelportal.readers.bonusgroup for generation 6 (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:44:01,104] INFO [GroupCoordinator 0]: Member consumer-console-consumer-61094-1-de1618b4-9a92-40f3-90d5-1642bb8c6f48 in group console-consumer-61094 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:44:01,104] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-61094 in state PreparingRebalance with old generation 1 (__consumer_offsets-41) (reason: removing member consumer-console-consumer-61094-1-de1618b4-9a92-40f3-90d5-1642bb8c6f48 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:44:01,105] INFO [GroupCoordinator 0]: Group console-consumer-61094 with generation 2 is now empty (__consumer_offsets-41) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:49:00,362] INFO [GroupCoordinator 0]: Member[group.instance.id None, member.id consumer-travelportal.readers.bonusgroup-2-e6e214c4-9b76-44b8-a489-33a696b042f0] in group travelportal.readers.bonusgroup has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:49:00,362] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.bonusgroup in state PreparingRebalance with old generation 6 (__consumer_offsets-32) (reason: removing member consumer-travelportal.readers.bonusgroup-2-e6e214c4-9b76-44b8-a489-33a696b042f0 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:49:00,363] INFO [GroupCoordinator 0]: Group travelportal.readers.bonusgroup with generation 7 is now empty (__consumer_offsets-32) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:49:49,864] INFO [Admin Manager on Broker 0]: Updating topic travelportal.readers with new configuration kafka.server.KafkaConfig@6f4e076a (kafka.server.AdminManager)
[2020-12-29 13:49:49,915] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2020-12-29 13:49:49,919] INFO Processing override for entityPath: topics/travelportal.readers with config: HashMap() (kafka.server.DynamicConfigManager)
[2020-12-29 13:49:50,238] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.bonusgroup in state PreparingRebalance with old generation 7 (__consumer_offsets-32) (reason: Adding new member consumer-travelportal.readers.bonusgroup-2-ba0091cd-53ea-4aec-88c7-0927a0b60976 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:49:50,240] INFO [GroupCoordinator 0]: Stabilized group travelportal.readers.bonusgroup generation 8 (__consumer_offsets-32) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:49:50,265] INFO [GroupCoordinator 0]: Assignment received from leader for group travelportal.readers.bonusgroup for generation 8 (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:50:42,043] INFO [GroupMetadataManager brokerId=0] Group travelportal.readers.statgroup transitioned to Dead in generation 3 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:50:42,046] INFO [GroupMetadataManager brokerId=0] Group console-consumer-61094 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:50:42,047] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 13:50:51,281] INFO [GroupCoordinator 0]: Member consumer-travelportal.readers.bonusgroup-2-ba0091cd-53ea-4aec-88c7-0927a0b60976 in group travelportal.readers.bonusgroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:50:51,281] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.bonusgroup in state PreparingRebalance with old generation 8 (__consumer_offsets-32) (reason: removing member consumer-travelportal.readers.bonusgroup-2-ba0091cd-53ea-4aec-88c7-0927a0b60976 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:50:51,282] INFO [GroupCoordinator 0]: Group travelportal.readers.bonusgroup with generation 9 is now empty (__consumer_offsets-32) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:57:25,122] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.bonusgroup in state PreparingRebalance with old generation 9 (__consumer_offsets-32) (reason: Adding new member consumer-travelportal.readers.bonusgroup-2-7e60aa8a-c506-474c-86a5-4894804a401e with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:57:25,123] INFO [GroupCoordinator 0]: Stabilized group travelportal.readers.bonusgroup generation 10 (__consumer_offsets-32) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:57:25,125] INFO [GroupCoordinator 0]: Assignment received from leader for group travelportal.readers.bonusgroup for generation 10 (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:57:25,243] INFO [GroupCoordinator 0]: Member[group.instance.id None, member.id consumer-travelportal.readers.bonusgroup-2-7e60aa8a-c506-474c-86a5-4894804a401e] in group travelportal.readers.bonusgroup has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:57:25,244] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.bonusgroup in state PreparingRebalance with old generation 10 (__consumer_offsets-32) (reason: removing member consumer-travelportal.readers.bonusgroup-2-7e60aa8a-c506-474c-86a5-4894804a401e on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 13:57:25,246] INFO [GroupCoordinator 0]: Group travelportal.readers.bonusgroup with generation 11 is now empty (__consumer_offsets-32) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:00:42,040] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:02:09,976] INFO [Admin Manager on Broker 0]: Updating topic travelportal.readers with new configuration kafka.server.KafkaConfig@6f4e076a (kafka.server.AdminManager)
[2020-12-29 14:02:09,988] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2020-12-29 14:02:09,990] INFO Processing override for entityPath: topics/travelportal.readers with config: HashMap() (kafka.server.DynamicConfigManager)
[2020-12-29 14:02:10,013] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2020-12-29 14:02:10,162] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.statgroup in state PreparingRebalance with old generation 0 (__consumer_offsets-23) (reason: Adding new member consumer-travelportal.readers.statgroup-2-0e6ecc50-fcc2-4627-9d18-3827654d075c with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:02:10,162] INFO [GroupCoordinator 0]: Stabilized group travelportal.readers.statgroup generation 1 (__consumer_offsets-23) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:02:10,173] INFO [GroupCoordinator 0]: Assignment received from leader for group travelportal.readers.statgroup for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:02:20,176] INFO [GroupCoordinator 0]: Member consumer-travelportal.readers.statgroup-2-0e6ecc50-fcc2-4627-9d18-3827654d075c in group travelportal.readers.statgroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:02:20,176] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.statgroup in state PreparingRebalance with old generation 1 (__consumer_offsets-23) (reason: removing member consumer-travelportal.readers.statgroup-2-0e6ecc50-fcc2-4627-9d18-3827654d075c on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:02:20,177] INFO [GroupCoordinator 0]: Group travelportal.readers.statgroup with generation 2 is now empty (__consumer_offsets-23) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:02:24,389] INFO [Admin Manager on Broker 0]: Updating topic travelportal.readers with new configuration kafka.server.KafkaConfig@6f4e076a (kafka.server.AdminManager)
[2020-12-29 14:02:24,398] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2020-12-29 14:02:24,400] INFO Processing override for entityPath: topics/travelportal.readers with config: HashMap() (kafka.server.DynamicConfigManager)
[2020-12-29 14:02:24,531] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.bonusgroup in state PreparingRebalance with old generation 11 (__consumer_offsets-32) (reason: Adding new member consumer-travelportal.readers.bonusgroup-2-6f850b58-865f-491d-8397-170d8bf16f4b with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:02:24,532] INFO [GroupCoordinator 0]: Stabilized group travelportal.readers.bonusgroup generation 12 (__consumer_offsets-32) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:02:24,543] INFO [GroupCoordinator 0]: Assignment received from leader for group travelportal.readers.bonusgroup for generation 12 (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:02:24,804] INFO [Admin Manager on Broker 0]: Updating topic travelportal.readers with new configuration kafka.server.KafkaConfig@6f4e076a (kafka.server.AdminManager)
[2020-12-29 14:02:24,813] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2020-12-29 14:02:24,815] INFO Processing override for entityPath: topics/travelportal.readers with config: HashMap() (kafka.server.DynamicConfigManager)
[2020-12-29 14:02:41,028] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.statgroup in state PreparingRebalance with old generation 2 (__consumer_offsets-23) (reason: Adding new member consumer-travelportal.readers.statgroup-2-0381a9d3-0822-45ec-9963-8827be2eecc4 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:02:41,029] INFO [GroupCoordinator 0]: Stabilized group travelportal.readers.statgroup generation 3 (__consumer_offsets-23) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:02:41,031] INFO [GroupCoordinator 0]: Assignment received from leader for group travelportal.readers.statgroup for generation 3 (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:03:42,478] INFO [GroupCoordinator 0]: Member[group.instance.id None, member.id consumer-travelportal.readers.statgroup-2-0381a9d3-0822-45ec-9963-8827be2eecc4] in group travelportal.readers.statgroup has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:03:42,478] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.statgroup in state PreparingRebalance with old generation 3 (__consumer_offsets-23) (reason: removing member consumer-travelportal.readers.statgroup-2-0381a9d3-0822-45ec-9963-8827be2eecc4 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:03:42,479] INFO [GroupCoordinator 0]: Group travelportal.readers.statgroup with generation 4 is now empty (__consumer_offsets-23) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:04:06,582] INFO [Admin Manager on Broker 0]: Updating topic travelportal.readers with new configuration kafka.server.KafkaConfig@6f4e076a (kafka.server.AdminManager)
[2020-12-29 14:04:06,592] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2020-12-29 14:04:06,594] INFO Processing override for entityPath: topics/travelportal.readers with config: HashMap() (kafka.server.DynamicConfigManager)
[2020-12-29 14:04:06,748] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.statgroup in state PreparingRebalance with old generation 4 (__consumer_offsets-23) (reason: Adding new member consumer-travelportal.readers.statgroup-2-85f8e942-cb04-41b1-b751-eaeba0af6944 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:04:06,749] INFO [GroupCoordinator 0]: Stabilized group travelportal.readers.statgroup generation 5 (__consumer_offsets-23) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:04:06,756] INFO [GroupCoordinator 0]: Assignment received from leader for group travelportal.readers.statgroup for generation 5 (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:07:19,792] INFO [GroupCoordinator 0]: Member consumer-travelportal.readers.statgroup-2-85f8e942-cb04-41b1-b751-eaeba0af6944 in group travelportal.readers.statgroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:07:19,792] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.statgroup in state PreparingRebalance with old generation 5 (__consumer_offsets-23) (reason: removing member consumer-travelportal.readers.statgroup-2-85f8e942-cb04-41b1-b751-eaeba0af6944 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:07:19,794] INFO [GroupCoordinator 0]: Group travelportal.readers.statgroup with generation 6 is now empty (__consumer_offsets-23) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:07:32,525] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.statgroup in state PreparingRebalance with old generation 6 (__consumer_offsets-23) (reason: Adding new member consumer-travelportal.readers.statgroup-2-0e942cf3-83bf-4231-a04a-bd6f816917b8 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:07:32,526] INFO [GroupCoordinator 0]: Stabilized group travelportal.readers.statgroup generation 7 (__consumer_offsets-23) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:07:32,529] INFO [GroupCoordinator 0]: Assignment received from leader for group travelportal.readers.statgroup for generation 7 (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:08:52,674] ERROR Error while writing to checkpoint file D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\replication-offset-checkpoint (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\replication-offset-checkpoint: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:384)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
	at java.base/java.nio.file.Files.move(Files.java:1421)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:913)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:114)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:92)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:59)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$6(ReplicaManager.scala:1673)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$6$adapted(ReplicaManager.scala:1672)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:553)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:551)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:920)
	at scala.collection.IterableOps$WithFilter.foreach(Iterable.scala:890)
	at kafka.server.ReplicaManager.checkpointHighWatermarks(ReplicaManager.scala:1672)
	at kafka.server.ReplicaManager.$anonfun$startHighWatermarkCheckPointThread$1(ReplicaManager.scala:267)
	at kafka.utils.KafkaScheduler.$anonfun$schedule$2(KafkaScheduler.scala:114)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
	Suppressed: java.nio.file.AccessDeniedException: D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\replication-offset-checkpoint.tmp -> D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\replication-offset-checkpoint
		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:309)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
		at java.base/java.nio.file.Files.move(Files.java:1421)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:910)
		... 18 more
[2020-12-29 14:08:52,678] WARN [ReplicaManager broker=0] Stopping serving replicas in dir D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka (kafka.server.ReplicaManager)
[2020-12-29 14:08:52,678] ERROR [ReplicaManager broker=0] Error while writing to highwatermark file in directory D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka (kafka.server.ReplicaManager)
org.apache.kafka.common.errors.KafkaStorageException: Error while writing to checkpoint file D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\replication-offset-checkpoint
Caused by: java.nio.file.FileSystemException: D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\replication-offset-checkpoint: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:384)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
	at java.base/java.nio.file.Files.move(Files.java:1421)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:913)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:114)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:92)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:59)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$6(ReplicaManager.scala:1673)
	at kafka.server.ReplicaManager.$anonfun$checkpointHighWatermarks$6$adapted(ReplicaManager.scala:1672)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:553)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:551)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:920)
	at scala.collection.IterableOps$WithFilter.foreach(Iterable.scala:890)
	at kafka.server.ReplicaManager.checkpointHighWatermarks(ReplicaManager.scala:1672)
	at kafka.server.ReplicaManager.$anonfun$startHighWatermarkCheckPointThread$1(ReplicaManager.scala:267)
	at kafka.utils.KafkaScheduler.$anonfun$schedule$2(KafkaScheduler.scala:114)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
	Suppressed: java.nio.file.AccessDeniedException: D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\replication-offset-checkpoint.tmp -> D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\replication-offset-checkpoint
		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:309)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
		at java.base/java.nio.file.Files.move(Files.java:1421)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:910)
		... 18 more
[2020-12-29 14:08:52,687] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, travelportal.readers-0, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-12-29 14:08:52,693] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, travelportal.readers-0, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaAlterLogDirsManager)
[2020-12-29 14:08:52,717] WARN [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-37,__consumer_offsets-38,__consumer_offsets-13,travelportal.readers-0,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40 and stopped moving logs for partitions  because they are in the failed log directory D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka. (kafka.server.ReplicaManager)
[2020-12-29 14:08:52,718] WARN Stopping serving logs in dir D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka (kafka.log.LogManager)
[2020-12-29 14:08:52,726] ERROR Shutdown broker because all log dirs in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka have failed (kafka.log.LogManager)
[2020-12-29 14:08:53,063] WARN Exception causing close of session 0x100090cb4eb0001: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2020-12-29 14:09:07,682] INFO Expiring session 0x100090cb4eb0001, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 14:37:34,516] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-12-29 14:37:34,516] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-12-29 14:37:34,516] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-12-29 14:37:34,516] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-12-29 14:37:34,518] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-12-29 14:37:34,527] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-12-29 14:37:34,529] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-12-29 14:37:34,551] INFO Server environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 14:37:34,551] INFO Server environment:host.name=192.168.0.230 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 14:37:34,551] INFO Server environment:java.version=11.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 14:37:34,551] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 14:37:34,551] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 14:37:34,552] INFO Server environment:java.class.path=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\activation-1.1.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\argparse4j-0.7.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\audience-annotations-0.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\commons-cli-1.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\commons-lang3-3.8.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-api-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-basic-auth-extension-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-file-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-json-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-mirror-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-mirror-client-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-runtime-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-transforms-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\hk2-api-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\hk2-locator-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\hk2-utils-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-annotations-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-core-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-databind-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.inject-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javassist-3.22.0-CR2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javassist-3.26.0-GA.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javax.servlet-api-3.1.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jaxb-api-2.3.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-client-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-common-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-container-servlet-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-hk2-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-media-jaxb-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-server-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jopt-simple-5.0.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-clients-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-log4j-appender-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-examples-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-scala_2.13-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-test-utils-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-tools-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-javadoc.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-scaladoc.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-sources.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-test-sources.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-test.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\log4j-1.2.17.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\lz4-java-1.7.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\maven-artifact-3.6.3.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\metrics-core-2.2.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-buffer-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-codec-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-common-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-handler-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-resolver-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-transport-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-transport-native-epoll-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-transport-native-unix-common-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\paranamer-2.8.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\plexus-utils-3.2.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\reflections-0.9.12.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\rocksdbjni-5.18.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-collection-compat_2.13-2.1.6.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-java8-compat_2.13-0.9.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-library-2.13.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-reflect-2.13.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\slf4j-api-1.7.30.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\snappy-java-1.1.7.3.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\validation-api-2.0.1.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\zookeeper-3.5.8.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\zookeeper-jute-3.5.8.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 14:37:34,554] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.2\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\development\version control\Git\cmd;D:\Software\posgres\pg11\bin;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\Gpg4win\..\GnuPG\bin;C:\Program Files\PuTTY\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.2\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\Daglemino\AppData\Local\Microsoft\WindowsApps;C:\tools\cuda\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\include;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\extra\CUPTI\libx;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 14:37:34,555] INFO Server environment:java.io.tmpdir=C:\Users\DAGLEM~1\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 14:37:34,555] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 14:37:34,556] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 14:37:34,557] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 14:37:34,558] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 14:37:34,558] INFO Server environment:user.name=Daglemino (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 14:37:34,559] INFO Server environment:user.home=C:\Users\Daglemino (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 14:37:34,559] INFO Server environment:user.dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 14:37:34,564] INFO Server environment:os.memory.free=493MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 14:37:34,564] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 14:37:34,565] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 14:37:34,568] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 14:37:34,568] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 14:37:34,569] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir data\zookeeper\version-2 snapdir data\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-12-29 14:37:34,588] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-12-29 14:37:34,592] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 24 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-12-29 14:37:34,595] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-12-29 14:37:34,612] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-12-29 14:37:34,623] INFO Reading snapshot data\zookeeper\version-2\snapshot.c8 (org.apache.zookeeper.server.persistence.FileSnap)
[2020-12-29 14:37:34,659] INFO Snapshotting: 0x107 to data\zookeeper\version-2\snapshot.107 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-12-29 14:37:34,686] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-12-29 14:37:39,349] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-12-29 14:37:39,619] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-12-29 14:37:39,673] INFO starting (kafka.server.KafkaServer)
[2020-12-29 14:37:39,674] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-12-29 14:37:39,691] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-12-29 14:37:39,715] INFO Client environment:zookeeper.version=3.5.8-f439ca583e70862c3068a1f2a7d4d068eec33315, built on 05/04/2020 15:53 GMT (org.apache.zookeeper.ZooKeeper)
[2020-12-29 14:37:39,715] INFO Client environment:host.name=192.168.0.230 (org.apache.zookeeper.ZooKeeper)
[2020-12-29 14:37:39,715] INFO Client environment:java.version=11.0.2 (org.apache.zookeeper.ZooKeeper)
[2020-12-29 14:37:39,716] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-12-29 14:37:39,716] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.2 (org.apache.zookeeper.ZooKeeper)
[2020-12-29 14:37:39,716] INFO Client environment:java.class.path=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\activation-1.1.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\argparse4j-0.7.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\audience-annotations-0.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\commons-cli-1.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\commons-lang3-3.8.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-api-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-basic-auth-extension-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-file-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-json-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-mirror-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-mirror-client-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-runtime-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\connect-transforms-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\hk2-api-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\hk2-locator-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\hk2-utils-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-annotations-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-core-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-databind-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.inject-2.5.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javassist-3.22.0-CR2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javassist-3.26.0-GA.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javax.servlet-api-3.1.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jaxb-api-2.3.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-client-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-common-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-container-servlet-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-hk2-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-media-jaxb-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jersey-server-2.28.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\jopt-simple-5.0.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-clients-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-log4j-appender-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-examples-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-scala_2.13-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-streams-test-utils-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka-tools-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-javadoc.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-scaladoc.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-sources.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-test-sources.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0-test.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\kafka_2.13-2.6.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\log4j-1.2.17.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\lz4-java-1.7.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\maven-artifact-3.6.3.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\metrics-core-2.2.0.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-buffer-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-codec-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-common-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-handler-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-resolver-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-transport-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-transport-native-epoll-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\netty-transport-native-unix-common-4.1.50.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\paranamer-2.8.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\plexus-utils-3.2.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\reflections-0.9.12.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\rocksdbjni-5.18.4.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-collection-compat_2.13-2.1.6.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-java8-compat_2.13-0.9.1.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-library-2.13.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\scala-reflect-2.13.2.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\slf4j-api-1.7.30.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\snappy-java-1.1.7.3.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\validation-api-2.0.1.Final.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\zookeeper-3.5.8.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\zookeeper-jute-3.5.8.jar;D:\development\java\studium\technikum-sks-master\project\Tools\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2020-12-29 14:37:39,719] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.2\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;D:\development\version control\Git\cmd;D:\Software\posgres\pg11\bin;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\Gpg4win\..\GnuPG\bin;C:\Program Files\PuTTY\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.2\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\Daglemino\AppData\Local\Microsoft\WindowsApps;C:\tools\cuda\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\include;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\extra\CUPTI\libx;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2020-12-29 14:37:39,719] INFO Client environment:java.io.tmpdir=C:\Users\DAGLEM~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-12-29 14:37:39,720] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-12-29 14:37:39,720] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2020-12-29 14:37:39,720] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-12-29 14:37:39,721] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2020-12-29 14:37:39,721] INFO Client environment:user.name=Daglemino (org.apache.zookeeper.ZooKeeper)
[2020-12-29 14:37:39,721] INFO Client environment:user.home=C:\Users\Daglemino (org.apache.zookeeper.ZooKeeper)
[2020-12-29 14:37:39,722] INFO Client environment:user.dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka (org.apache.zookeeper.ZooKeeper)
[2020-12-29 14:37:39,722] INFO Client environment:os.memory.free=1013MB (org.apache.zookeeper.ZooKeeper)
[2020-12-29 14:37:39,722] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-12-29 14:37:39,723] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-12-29 14:37:39,725] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@45fd9a4d (org.apache.zookeeper.ZooKeeper)
[2020-12-29 14:37:39,735] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-12-29 14:37:39,741] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-12-29 14:37:39,743] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-12-29 14:37:39,749] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-12-29 14:37:39,752] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:62081, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-12-29 14:37:39,759] INFO Creating new log file: log.108 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-12-29 14:37:39,768] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100094133900000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2020-12-29 14:37:39,770] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-12-29 14:37:39,977] INFO Cluster ID = faeabPsTRvy-g5J7XJiYXg (kafka.server.KafkaServer)
[2020-12-29 14:37:40,021] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.6-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = data\kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.6-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-12-29 14:37:40,030] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.6-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = data\kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.6-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-12-29 14:37:40,065] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-12-29 14:37:40,066] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-12-29 14:37:40,068] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-12-29 14:37:40,104] INFO Loading logs from log dirs ArraySeq(D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,108] INFO Attempting recovery for all logs in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka since no clean shutdown file was found (kafka.log.LogManager)
[2020-12-29 14:37:40,153] INFO [Log partition=travelportal.readers-0, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,154] INFO [Log partition=travelportal.readers-0, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,183] INFO [ProducerStateManager partition=travelportal.readers-0] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2020-12-29 14:37:40,204] INFO [Log partition=travelportal.readers-0, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,209] INFO [ProducerStateManager partition=travelportal.readers-0] Loading producer state from snapshot file 'D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\travelportal.readers-0\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2020-12-29 14:37:40,233] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\travelportal.readers-0, topic=travelportal.readers, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=4) with 1 segments in 116ms (1/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,237] INFO [Log partition=__consumer_offsets-0, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,237] INFO [Log partition=__consumer_offsets-0, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,256] INFO [Log partition=__consumer_offsets-0, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,259] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-0, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (2/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,261] INFO [Log partition=__consumer_offsets-1, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,261] INFO [Log partition=__consumer_offsets-1, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,268] INFO [Log partition=__consumer_offsets-1, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,271] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-1, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (3/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,273] INFO [Log partition=__consumer_offsets-10, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,277] INFO [Log partition=__consumer_offsets-10, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,284] INFO [Log partition=__consumer_offsets-10, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,287] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-10, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (4/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,289] INFO [Log partition=__consumer_offsets-11, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,289] INFO [Log partition=__consumer_offsets-11, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,301] INFO [Log partition=__consumer_offsets-11, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,304] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-11, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (5/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,306] INFO [Log partition=__consumer_offsets-12, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,306] INFO [Log partition=__consumer_offsets-12, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,320] INFO [Log partition=__consumer_offsets-12, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,323] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-12, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (6/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,332] INFO [Log partition=__consumer_offsets-13, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,333] INFO [Log partition=__consumer_offsets-13, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,343] INFO [Log partition=__consumer_offsets-13, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,347] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-13, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (7/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,349] INFO [Log partition=__consumer_offsets-14, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,352] INFO [Log partition=__consumer_offsets-14, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,361] INFO [Log partition=__consumer_offsets-14, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,365] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-14, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (8/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,367] INFO [Log partition=__consumer_offsets-15, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,368] INFO [Log partition=__consumer_offsets-15, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,375] INFO [Log partition=__consumer_offsets-15, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,381] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-15, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (9/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,382] INFO [Log partition=__consumer_offsets-16, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,382] INFO [Log partition=__consumer_offsets-16, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,390] INFO [Log partition=__consumer_offsets-16, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,393] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-16, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (10/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,394] INFO [Log partition=__consumer_offsets-17, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,395] INFO [Log partition=__consumer_offsets-17, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,406] INFO [Log partition=__consumer_offsets-17, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,408] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-17, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (11/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,410] INFO [Log partition=__consumer_offsets-18, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,411] INFO [Log partition=__consumer_offsets-18, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,418] INFO [Log partition=__consumer_offsets-18, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,420] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-18, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (12/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,422] INFO [Log partition=__consumer_offsets-19, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,424] INFO [Log partition=__consumer_offsets-19, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,432] INFO [Log partition=__consumer_offsets-19, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,435] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-19, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (13/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,437] INFO [Log partition=__consumer_offsets-2, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,437] INFO [Log partition=__consumer_offsets-2, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,457] INFO [Log partition=__consumer_offsets-2, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,459] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-2, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 23ms (14/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,462] INFO [Log partition=__consumer_offsets-20, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,462] INFO [Log partition=__consumer_offsets-20, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,470] INFO [Log partition=__consumer_offsets-20, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,472] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-20, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (15/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,474] INFO [Log partition=__consumer_offsets-21, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,478] INFO [Log partition=__consumer_offsets-21, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,485] INFO [Log partition=__consumer_offsets-21, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,489] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-21, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (16/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,492] INFO [Log partition=__consumer_offsets-22, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,493] INFO [Log partition=__consumer_offsets-22, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,503] INFO [Log partition=__consumer_offsets-22, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,506] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-22, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (17/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,510] INFO [Log partition=__consumer_offsets-23, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,510] INFO [Log partition=__consumer_offsets-23, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,516] INFO [ProducerStateManager partition=__consumer_offsets-23] Writing producer snapshot at offset 13 (kafka.log.ProducerStateManager)
[2020-12-29 14:37:40,530] INFO [Log partition=__consumer_offsets-23, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 13 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,531] INFO [ProducerStateManager partition=__consumer_offsets-23] Loading producer state from snapshot file 'D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-23\00000000000000000013.snapshot' (kafka.log.ProducerStateManager)
[2020-12-29 14:37:40,534] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-23, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=13) with 1 segments in 27ms (18/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,537] INFO [Log partition=__consumer_offsets-24, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,537] INFO [Log partition=__consumer_offsets-24, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,544] INFO [Log partition=__consumer_offsets-24, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,546] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-24, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (19/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,548] INFO [Log partition=__consumer_offsets-25, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,548] INFO [Log partition=__consumer_offsets-25, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,555] INFO [Log partition=__consumer_offsets-25, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,557] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-25, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (20/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,559] INFO [Log partition=__consumer_offsets-26, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,559] INFO [Log partition=__consumer_offsets-26, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,566] INFO [Log partition=__consumer_offsets-26, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,568] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-26, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (21/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,570] INFO [Log partition=__consumer_offsets-27, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,571] INFO [Log partition=__consumer_offsets-27, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,584] INFO [Log partition=__consumer_offsets-27, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,586] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-27, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (22/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,594] INFO [Log partition=__consumer_offsets-28, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,594] INFO [Log partition=__consumer_offsets-28, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,603] INFO [Log partition=__consumer_offsets-28, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,605] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-28, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (23/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,607] INFO [Log partition=__consumer_offsets-29, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,608] INFO [Log partition=__consumer_offsets-29, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,617] INFO [Log partition=__consumer_offsets-29, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,619] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-29, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (24/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,622] INFO [Log partition=__consumer_offsets-3, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,622] INFO [Log partition=__consumer_offsets-3, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,635] INFO [Log partition=__consumer_offsets-3, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,638] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-3, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (25/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,641] INFO [Log partition=__consumer_offsets-30, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,643] INFO [Log partition=__consumer_offsets-30, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,651] INFO [Log partition=__consumer_offsets-30, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,654] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-30, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (26/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,656] INFO [Log partition=__consumer_offsets-31, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,659] INFO [Log partition=__consumer_offsets-31, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,667] INFO [Log partition=__consumer_offsets-31, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,669] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-31, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (27/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,672] INFO [Log partition=__consumer_offsets-32, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,672] INFO [Log partition=__consumer_offsets-32, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,681] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 16 (kafka.log.ProducerStateManager)
[2020-12-29 14:37:40,691] INFO [Log partition=__consumer_offsets-32, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 16 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,692] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file 'D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-32\00000000000000000016.snapshot' (kafka.log.ProducerStateManager)
[2020-12-29 14:37:40,695] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-32, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=16) with 1 segments in 25ms (28/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,696] INFO [Log partition=__consumer_offsets-33, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,696] INFO [Log partition=__consumer_offsets-33, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,709] INFO [Log partition=__consumer_offsets-33, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,711] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-33, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (29/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,713] INFO [Log partition=__consumer_offsets-34, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,724] INFO [Log partition=__consumer_offsets-34, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,731] INFO [Log partition=__consumer_offsets-34, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,733] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-34, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (30/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,735] INFO [Log partition=__consumer_offsets-35, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,736] INFO [Log partition=__consumer_offsets-35, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,745] INFO [Log partition=__consumer_offsets-35, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,747] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-35, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (31/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,749] INFO [Log partition=__consumer_offsets-36, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,749] INFO [Log partition=__consumer_offsets-36, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,759] INFO [Log partition=__consumer_offsets-36, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,762] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-36, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (32/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,764] INFO [Log partition=__consumer_offsets-37, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,764] INFO [Log partition=__consumer_offsets-37, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,774] INFO [Log partition=__consumer_offsets-37, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,778] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-37, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (33/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,780] INFO [Log partition=__consumer_offsets-38, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,781] INFO [Log partition=__consumer_offsets-38, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,790] INFO [Log partition=__consumer_offsets-38, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,792] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-38, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (34/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,794] INFO [Log partition=__consumer_offsets-39, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,795] INFO [Log partition=__consumer_offsets-39, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,802] INFO [Log partition=__consumer_offsets-39, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,804] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-39, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (35/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,806] INFO [Log partition=__consumer_offsets-4, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,806] INFO [Log partition=__consumer_offsets-4, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,814] INFO [Log partition=__consumer_offsets-4, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,815] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-4, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (36/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,817] INFO [Log partition=__consumer_offsets-40, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,823] INFO [Log partition=__consumer_offsets-40, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,831] INFO [Log partition=__consumer_offsets-40, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,839] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-40, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (37/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,842] INFO [Log partition=__consumer_offsets-41, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,843] INFO [Log partition=__consumer_offsets-41, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,847] INFO [ProducerStateManager partition=__consumer_offsets-41] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-12-29 14:37:40,860] INFO [Log partition=__consumer_offsets-41, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,861] INFO [ProducerStateManager partition=__consumer_offsets-41] Loading producer state from snapshot file 'D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-41\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-12-29 14:37:40,863] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-41, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 23ms (38/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,866] INFO [Log partition=__consumer_offsets-42, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,866] INFO [Log partition=__consumer_offsets-42, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,873] INFO [Log partition=__consumer_offsets-42, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,876] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-42, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (39/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,877] INFO [Log partition=__consumer_offsets-43, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,878] INFO [Log partition=__consumer_offsets-43, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,887] INFO [Log partition=__consumer_offsets-43, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,889] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-43, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (40/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,891] INFO [Log partition=__consumer_offsets-44, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,892] INFO [Log partition=__consumer_offsets-44, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,903] INFO [Log partition=__consumer_offsets-44, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,905] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-44, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (41/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,906] INFO [Log partition=__consumer_offsets-45, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,907] INFO [Log partition=__consumer_offsets-45, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,914] INFO [Log partition=__consumer_offsets-45, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,915] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-45, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (42/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,917] INFO [Log partition=__consumer_offsets-46, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,918] INFO [Log partition=__consumer_offsets-46, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,925] INFO [Log partition=__consumer_offsets-46, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,927] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-46, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (43/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,929] INFO [Log partition=__consumer_offsets-47, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,929] INFO [Log partition=__consumer_offsets-47, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,935] INFO [Log partition=__consumer_offsets-47, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,937] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-47, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (44/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,938] INFO [Log partition=__consumer_offsets-48, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,941] INFO [Log partition=__consumer_offsets-48, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,948] INFO [Log partition=__consumer_offsets-48, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,949] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-48, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (45/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,951] INFO [Log partition=__consumer_offsets-49, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,951] INFO [Log partition=__consumer_offsets-49, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,958] INFO [Log partition=__consumer_offsets-49, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,959] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-49, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (46/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,960] INFO [Log partition=__consumer_offsets-5, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,961] INFO [Log partition=__consumer_offsets-5, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,967] INFO [Log partition=__consumer_offsets-5, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,969] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-5, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (47/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:40,977] INFO [Log partition=__consumer_offsets-6, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:40,983] INFO [Log partition=__consumer_offsets-6, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:40,994] INFO [Log partition=__consumer_offsets-6, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:41,004] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-6, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 28ms (48/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:41,005] INFO [Log partition=__consumer_offsets-7, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:41,011] INFO [Log partition=__consumer_offsets-7, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:41,019] INFO [Log partition=__consumer_offsets-7, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:41,020] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-7, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (49/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:41,022] INFO [Log partition=__consumer_offsets-8, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:41,025] INFO [Log partition=__consumer_offsets-8, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:41,031] INFO [Log partition=__consumer_offsets-8, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:41,032] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-8, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (50/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:41,034] INFO [Log partition=__consumer_offsets-9, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-12-29 14:37:41,035] INFO [Log partition=__consumer_offsets-9, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:41,047] INFO [Log partition=__consumer_offsets-9, dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-12-29 14:37:41,048] INFO Completed load of Log(dir=D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka\__consumer_offsets-9, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (51/51 loaded in D:\development\java\studium\technikum-sks-master\project\Tools\kafka\data\kafka) (kafka.log.LogManager)
[2020-12-29 14:37:41,051] INFO Loaded 51 logs in 946ms. (kafka.log.LogManager)
[2020-12-29 14:37:41,060] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-12-29 14:37:41,061] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-12-29 14:37:41,419] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-12-29 14:37:41,479] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2020-12-29 14:37:41,497] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 14:37:41,502] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 14:37:41,502] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 14:37:41,502] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 14:37:41,519] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-12-29 14:37:41,573] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-12-29 14:37:41,604] INFO Stat of the created znode at /brokers/ids/0 is: 278,278,1609249061595,1609249061595,1,0,0,72067769680527360,196,0,278
 (kafka.zk.KafkaZkClient)
[2020-12-29 14:37:41,607] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://192.168.0.230:9092, czxid (broker epoch): 278 (kafka.zk.KafkaZkClient)
[2020-12-29 14:37:41,675] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 14:37:41,680] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 14:37:41,682] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 14:37:41,715] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:37:41,716] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:37:41,725] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:41,737] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:4000,blockEndProducerId:4999) by writing to Zk with path version 5 (kafka.coordinator.transaction.ProducerIdManager)
[2020-12-29 14:37:41,771] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-12-29 14:37:41,775] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-12-29 14:37:41,785] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-12-29 14:37:41,820] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-12-29 14:37:41,831] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-12-29 14:37:41,834] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2020-12-29 14:37:41,843] INFO Processing override for entityPath: topics/travelportal.readers with config: HashMap() (kafka.server.DynamicConfigManager)
[2020-12-29 14:37:41,854] INFO Processing override for entityPath: topics/travelportal.readers with config: HashMap() (kafka.server.DynamicConfigManager)
[2020-12-29 14:37:41,861] INFO Processing override for entityPath: topics/travelportal.readers with config: HashMap() (kafka.server.DynamicConfigManager)
[2020-12-29 14:37:41,864] INFO [SocketServer brokerId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2020-12-29 14:37:41,867] INFO Processing override for entityPath: topics/travelportal.readers with config: HashMap() (kafka.server.DynamicConfigManager)
[2020-12-29 14:37:41,878] INFO Processing override for entityPath: topics/travelportal.readers with config: HashMap() (kafka.server.DynamicConfigManager)
[2020-12-29 14:37:41,883] INFO [SocketServer brokerId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2020-12-29 14:37:41,887] INFO [SocketServer brokerId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2020-12-29 14:37:41,902] INFO Kafka version: 2.6.0 (org.apache.kafka.common.utils.AppInfoParser)
[2020-12-29 14:37:41,903] INFO Kafka commitId: 62abe01bee039651 (org.apache.kafka.common.utils.AppInfoParser)
[2020-12-29 14:37:41,904] INFO Kafka startTimeMs: 1609249061894 (org.apache.kafka.common.utils.AppInfoParser)
[2020-12-29 14:37:41,908] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-12-29 14:37:42,029] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, travelportal.readers-0, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-12-29 14:37:42,042] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,057] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,063] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 3 (kafka.cluster.Partition)
[2020-12-29 14:37:42,064] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,067] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,072] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,077] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,081] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,085] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,090] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,093] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,096] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,102] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,106] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,109] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,112] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,115] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,119] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,123] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,126] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,129] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,131] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,135] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,138] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,142] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 16 (kafka.cluster.Partition)
[2020-12-29 14:37:42,142] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,145] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,148] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,152] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,155] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,158] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,161] INFO [Partition travelportal.readers-0 broker=0] Log loaded for partition travelportal.readers-0 with initial high watermark 4 (kafka.cluster.Partition)
[2020-12-29 14:37:42,161] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 13 (kafka.cluster.Partition)
[2020-12-29 14:37:42,162] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,165] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,168] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,171] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,175] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,178] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,181] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,184] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,188] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,192] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,200] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,204] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,208] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,211] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,215] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,217] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,220] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,223] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2020-12-29 14:37:42,231] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,233] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,235] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,237] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,238] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 6 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,242] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,242] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 7 milliseconds, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,242] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,243] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,244] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,244] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,245] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,247] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,248] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,248] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,249] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,249] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,249] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,250] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,250] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,256] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,258] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,259] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,259] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,259] INFO Static member MemberMetadata(memberId=consumer-console-consumer-61094-1-de1618b4-9a92-40f3-90d5-1642bb8c6f48, groupInstanceId=Some(null), clientId=consumer-console-consumer-61094-1, clientHost=/192.168.0.230, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ).groupInstanceId of group console-consumer-61094 loaded with member id consumer-console-consumer-61094-1-de1618b4-9a92-40f3-90d5-1642bb8c6f48 at generation 1. (kafka.coordinator.group.GroupMetadata$)
[2020-12-29 14:37:42,260] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,260] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,261] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,261] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,262] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,262] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 25 milliseconds, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,263] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,263] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 22 milliseconds, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,263] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,264] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 22 milliseconds, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,264] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,265] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 22 milliseconds, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,265] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,266] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 22 milliseconds, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,272] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,273] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 29 milliseconds, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,273] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,274] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 29 milliseconds, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,274] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,275] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 27 milliseconds, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,275] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,275] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 27 milliseconds, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,276] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,276] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 28 milliseconds, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,277] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,279] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 30 milliseconds, of which 30 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,280] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,281] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 32 milliseconds, of which 32 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,281] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,282] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 33 milliseconds, of which 33 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,282] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,283] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 33 milliseconds, of which 33 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,283] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,285] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 34 milliseconds, of which 34 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,285] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,289] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 33 milliseconds, of which 33 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,293] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,294] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 36 milliseconds, of which 36 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,294] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,295] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 36 milliseconds, of which 36 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,295] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,296] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 37 milliseconds, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,296] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,297] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 38 milliseconds, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,298] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,298] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 38 milliseconds, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,298] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,299] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 38 milliseconds, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,299] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,303] INFO Static member MemberMetadata(memberId=consumer-travelportal.readers.bonusgroup-2-667a52cd-0a3e-4be5-b4cd-49f8e7a6a900, groupInstanceId=Some(null), clientId=consumer-travelportal.readers.bonusgroup-2, clientHost=/192.168.0.230, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ).groupInstanceId of group travelportal.readers.bonusgroup loaded with member id consumer-travelportal.readers.bonusgroup-2-667a52cd-0a3e-4be5-b4cd-49f8e7a6a900 at generation 1. (kafka.coordinator.group.GroupMetadata$)
[2020-12-29 14:37:42,306] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,307] INFO Static member MemberMetadata(memberId=consumer-travelportal.readers.bonusgroup-2-667a52cd-0a3e-4be5-b4cd-49f8e7a6a900, groupInstanceId=Some(null), clientId=consumer-travelportal.readers.bonusgroup-2, clientHost=/192.168.0.230, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ).groupInstanceId of group travelportal.readers.bonusgroup loaded with member id consumer-travelportal.readers.bonusgroup-2-667a52cd-0a3e-4be5-b4cd-49f8e7a6a900 at generation 2. (kafka.coordinator.group.GroupMetadata$)
[2020-12-29 14:37:42,310] INFO Static member MemberMetadata(memberId=consumer-travelportal.readers.bonusgroup-2-2144474b-3fde-4fe1-92bc-4a2404fba6f8, groupInstanceId=Some(null), clientId=consumer-travelportal.readers.bonusgroup-2, clientHost=/192.168.0.230, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ).groupInstanceId of group travelportal.readers.bonusgroup loaded with member id consumer-travelportal.readers.bonusgroup-2-2144474b-3fde-4fe1-92bc-4a2404fba6f8 at generation 4. (kafka.coordinator.group.GroupMetadata$)
[2020-12-29 14:37:42,313] INFO Static member MemberMetadata(memberId=consumer-travelportal.readers.bonusgroup-2-e6e214c4-9b76-44b8-a489-33a696b042f0, groupInstanceId=Some(null), clientId=consumer-travelportal.readers.bonusgroup-2, clientHost=/192.168.0.230, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ).groupInstanceId of group travelportal.readers.bonusgroup loaded with member id consumer-travelportal.readers.bonusgroup-2-e6e214c4-9b76-44b8-a489-33a696b042f0 at generation 6. (kafka.coordinator.group.GroupMetadata$)
[2020-12-29 14:37:42,316] INFO Static member MemberMetadata(memberId=consumer-travelportal.readers.bonusgroup-2-ba0091cd-53ea-4aec-88c7-0927a0b60976, groupInstanceId=Some(null), clientId=consumer-travelportal.readers.bonusgroup-2, clientHost=/192.168.0.230, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ).groupInstanceId of group travelportal.readers.bonusgroup loaded with member id consumer-travelportal.readers.bonusgroup-2-ba0091cd-53ea-4aec-88c7-0927a0b60976 at generation 8. (kafka.coordinator.group.GroupMetadata$)
[2020-12-29 14:37:42,320] INFO Static member MemberMetadata(memberId=consumer-travelportal.readers.bonusgroup-2-7e60aa8a-c506-474c-86a5-4894804a401e, groupInstanceId=Some(null), clientId=consumer-travelportal.readers.bonusgroup-2, clientHost=/192.168.0.230, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ).groupInstanceId of group travelportal.readers.bonusgroup loaded with member id consumer-travelportal.readers.bonusgroup-2-7e60aa8a-c506-474c-86a5-4894804a401e at generation 10. (kafka.coordinator.group.GroupMetadata$)
[2020-12-29 14:37:42,326] INFO Static member MemberMetadata(memberId=consumer-travelportal.readers.bonusgroup-2-6f850b58-865f-491d-8397-170d8bf16f4b, groupInstanceId=Some(null), clientId=consumer-travelportal.readers.bonusgroup-2, clientHost=/192.168.0.230, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ).groupInstanceId of group travelportal.readers.bonusgroup loaded with member id consumer-travelportal.readers.bonusgroup-2-6f850b58-865f-491d-8397-170d8bf16f4b at generation 12. (kafka.coordinator.group.GroupMetadata$)
[2020-12-29 14:37:42,330] INFO [GroupCoordinator 0]: Loading group metadata for travelportal.readers.bonusgroup with generation 12 (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:37:42,337] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 76 milliseconds, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,337] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 75 milliseconds, of which 75 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,338] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 76 milliseconds, of which 76 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,339] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 76 milliseconds, of which 76 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,342] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 78 milliseconds, of which 78 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,342] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 77 milliseconds, of which 77 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,344] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 72 milliseconds, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,349] INFO Static member MemberMetadata(memberId=consumer-travelportal.readers.statgroup-2-bd6cd563-b3d4-4679-9818-cb582e98096a, groupInstanceId=Some(null), clientId=consumer-travelportal.readers.statgroup-2, clientHost=/192.168.0.230, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ).groupInstanceId of group travelportal.readers.statgroup loaded with member id consumer-travelportal.readers.statgroup-2-bd6cd563-b3d4-4679-9818-cb582e98096a at generation 1. (kafka.coordinator.group.GroupMetadata$)
[2020-12-29 14:37:42,349] INFO Static member MemberMetadata(memberId=consumer-travelportal.readers.statgroup-2-bd6cd563-b3d4-4679-9818-cb582e98096a, groupInstanceId=Some(null), clientId=consumer-travelportal.readers.statgroup-2, clientHost=/192.168.0.230, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ).groupInstanceId of group travelportal.readers.statgroup loaded with member id consumer-travelportal.readers.statgroup-2-bd6cd563-b3d4-4679-9818-cb582e98096a at generation 2. (kafka.coordinator.group.GroupMetadata$)
[2020-12-29 14:37:42,350] INFO Static member MemberMetadata(memberId=consumer-travelportal.readers.statgroup-2-0e6ecc50-fcc2-4627-9d18-3827654d075c, groupInstanceId=Some(null), clientId=consumer-travelportal.readers.statgroup-2, clientHost=/192.168.0.230, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ).groupInstanceId of group travelportal.readers.statgroup loaded with member id consumer-travelportal.readers.statgroup-2-0e6ecc50-fcc2-4627-9d18-3827654d075c at generation 1. (kafka.coordinator.group.GroupMetadata$)
[2020-12-29 14:37:42,354] INFO Static member MemberMetadata(memberId=consumer-travelportal.readers.statgroup-2-0381a9d3-0822-45ec-9963-8827be2eecc4, groupInstanceId=Some(null), clientId=consumer-travelportal.readers.statgroup-2, clientHost=/192.168.0.230, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ).groupInstanceId of group travelportal.readers.statgroup loaded with member id consumer-travelportal.readers.statgroup-2-0381a9d3-0822-45ec-9963-8827be2eecc4 at generation 3. (kafka.coordinator.group.GroupMetadata$)
[2020-12-29 14:37:42,358] INFO Static member MemberMetadata(memberId=consumer-travelportal.readers.statgroup-2-85f8e942-cb04-41b1-b751-eaeba0af6944, groupInstanceId=Some(null), clientId=consumer-travelportal.readers.statgroup-2, clientHost=/192.168.0.230, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ).groupInstanceId of group travelportal.readers.statgroup loaded with member id consumer-travelportal.readers.statgroup-2-85f8e942-cb04-41b1-b751-eaeba0af6944 at generation 5. (kafka.coordinator.group.GroupMetadata$)
[2020-12-29 14:37:42,358] INFO Static member MemberMetadata(memberId=consumer-travelportal.readers.statgroup-2-0e942cf3-83bf-4231-a04a-bd6f816917b8, groupInstanceId=Some(null), clientId=consumer-travelportal.readers.statgroup-2, clientHost=/192.168.0.230, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ).groupInstanceId of group travelportal.readers.statgroup loaded with member id consumer-travelportal.readers.statgroup-2-0e942cf3-83bf-4231-a04a-bd6f816917b8 at generation 7. (kafka.coordinator.group.GroupMetadata$)
[2020-12-29 14:37:42,359] INFO [GroupCoordinator 0]: Loading group metadata for travelportal.readers.statgroup with generation 7 (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:37:42,360] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 87 milliseconds, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,360] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 86 milliseconds, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,361] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 86 milliseconds, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,362] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 86 milliseconds, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,366] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 89 milliseconds, of which 89 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,366] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 86 milliseconds, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,367] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 86 milliseconds, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,368] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 86 milliseconds, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,368] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 85 milliseconds, of which 85 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,374] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 89 milliseconds, of which 89 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,376] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 83 milliseconds, of which 83 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,377] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 83 milliseconds, of which 83 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,378] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 83 milliseconds, of which 83 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,379] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 83 milliseconds, of which 83 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,379] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 82 milliseconds, of which 82 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,380] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 82 milliseconds, of which 82 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,381] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 82 milliseconds, of which 82 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,381] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 75 milliseconds, of which 75 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:42,382] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 74 milliseconds, of which 74 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:37:46,570] INFO [Admin Manager on Broker 0]: Updating topic travelportal.readers with new configuration kafka.server.KafkaConfig@6f4e076a (kafka.server.AdminManager)
[2020-12-29 14:37:46,581] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2020-12-29 14:37:46,583] INFO Processing override for entityPath: topics/travelportal.readers with config: HashMap() (kafka.server.DynamicConfigManager)
[2020-12-29 14:37:52,339] INFO [GroupCoordinator 0]: Member consumer-travelportal.readers.bonusgroup-2-6f850b58-865f-491d-8397-170d8bf16f4b in group travelportal.readers.bonusgroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:37:52,341] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.bonusgroup in state PreparingRebalance with old generation 12 (__consumer_offsets-32) (reason: removing member consumer-travelportal.readers.bonusgroup-2-6f850b58-865f-491d-8397-170d8bf16f4b on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:37:52,343] INFO [GroupCoordinator 0]: Group travelportal.readers.bonusgroup with generation 13 is now empty (__consumer_offsets-32) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:37:52,366] INFO [GroupCoordinator 0]: Member consumer-travelportal.readers.statgroup-2-0e942cf3-83bf-4231-a04a-bd6f816917b8 in group travelportal.readers.statgroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:37:52,367] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.statgroup in state PreparingRebalance with old generation 7 (__consumer_offsets-23) (reason: removing member consumer-travelportal.readers.statgroup-2-0e942cf3-83bf-4231-a04a-bd6f816917b8 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:37:52,368] INFO [GroupCoordinator 0]: Group travelportal.readers.statgroup with generation 8 is now empty (__consumer_offsets-23) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:38:12,236] INFO [Admin Manager on Broker 0]: Updating topic travelportal.readers with new configuration kafka.server.KafkaConfig@6f4e076a (kafka.server.AdminManager)
[2020-12-29 14:38:12,245] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2020-12-29 14:38:12,247] INFO Processing override for entityPath: topics/travelportal.readers with config: HashMap() (kafka.server.DynamicConfigManager)
[2020-12-29 14:38:12,374] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.statgroup in state PreparingRebalance with old generation 8 (__consumer_offsets-23) (reason: Adding new member consumer-travelportal.readers.statgroup-2-218a4234-1749-43dc-8dcb-c18fb48927b0 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:38:12,377] INFO [GroupCoordinator 0]: Stabilized group travelportal.readers.statgroup generation 9 (__consumer_offsets-23) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:38:12,386] INFO [GroupCoordinator 0]: Assignment received from leader for group travelportal.readers.statgroup for generation 9 (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:38:12,540] INFO [Admin Manager on Broker 0]: Updating topic travelportal.readers with new configuration kafka.server.KafkaConfig@6f4e076a (kafka.server.AdminManager)
[2020-12-29 14:38:12,550] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2020-12-29 14:38:12,554] INFO Processing override for entityPath: topics/travelportal.readers with config: HashMap() (kafka.server.DynamicConfigManager)
[2020-12-29 14:38:12,658] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.bonusgroup in state PreparingRebalance with old generation 13 (__consumer_offsets-32) (reason: Adding new member consumer-travelportal.readers.bonusgroup-2-f86f673c-64cb-4e9d-a1cd-14e6caf43fe4 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:38:12,659] INFO [GroupCoordinator 0]: Stabilized group travelportal.readers.bonusgroup generation 14 (__consumer_offsets-32) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:38:12,665] INFO [GroupCoordinator 0]: Assignment received from leader for group travelportal.readers.bonusgroup for generation 14 (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:39:19,584] INFO [GroupCoordinator 0]: Member consumer-travelportal.readers.statgroup-2-218a4234-1749-43dc-8dcb-c18fb48927b0 in group travelportal.readers.statgroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:39:19,584] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.statgroup in state PreparingRebalance with old generation 9 (__consumer_offsets-23) (reason: removing member consumer-travelportal.readers.statgroup-2-218a4234-1749-43dc-8dcb-c18fb48927b0 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:39:19,586] INFO [GroupCoordinator 0]: Group travelportal.readers.statgroup with generation 10 is now empty (__consumer_offsets-23) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:39:25,887] INFO [GroupCoordinator 0]: Member consumer-travelportal.readers.bonusgroup-2-f86f673c-64cb-4e9d-a1cd-14e6caf43fe4 in group travelportal.readers.bonusgroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:39:25,887] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.bonusgroup in state PreparingRebalance with old generation 14 (__consumer_offsets-32) (reason: removing member consumer-travelportal.readers.bonusgroup-2-f86f673c-64cb-4e9d-a1cd-14e6caf43fe4 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:39:25,889] INFO [GroupCoordinator 0]: Group travelportal.readers.bonusgroup with generation 15 is now empty (__consumer_offsets-32) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:42:52,662] INFO [Admin Manager on Broker 0]: Updating topic travelportal.readers with new configuration kafka.server.KafkaConfig@6f4e076a (kafka.server.AdminManager)
[2020-12-29 14:42:52,671] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2020-12-29 14:42:52,673] INFO Processing override for entityPath: topics/travelportal.readers with config: HashMap() (kafka.server.DynamicConfigManager)
[2020-12-29 14:42:52,781] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.bonusgroup in state PreparingRebalance with old generation 15 (__consumer_offsets-32) (reason: Adding new member consumer-travelportal.readers.bonusgroup-2-6bf229e1-9b99-4813-9b65-69152fdc4f90 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:42:52,782] INFO [GroupCoordinator 0]: Stabilized group travelportal.readers.bonusgroup generation 16 (__consumer_offsets-32) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:42:52,788] INFO [GroupCoordinator 0]: Assignment received from leader for group travelportal.readers.bonusgroup for generation 16 (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:42:56,769] INFO [Admin Manager on Broker 0]: Updating topic travelportal.readers with new configuration kafka.server.KafkaConfig@6f4e076a (kafka.server.AdminManager)
[2020-12-29 14:42:56,778] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2020-12-29 14:42:56,780] INFO Processing override for entityPath: topics/travelportal.readers with config: HashMap() (kafka.server.DynamicConfigManager)
[2020-12-29 14:42:56,889] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.statgroup in state PreparingRebalance with old generation 10 (__consumer_offsets-23) (reason: Adding new member consumer-travelportal.readers.statgroup-2-168d4ca9-e8da-4d66-b9e9-7f1c3d2fdbff with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:42:56,890] INFO [GroupCoordinator 0]: Stabilized group travelportal.readers.statgroup generation 11 (__consumer_offsets-23) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:42:56,896] INFO [GroupCoordinator 0]: Assignment received from leader for group travelportal.readers.statgroup for generation 11 (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 14:47:41,719] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 14:57:41,717] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-12-29 15:00:38,988] INFO [GroupCoordinator 0]: Member consumer-travelportal.readers.bonusgroup-2-6bf229e1-9b99-4813-9b65-69152fdc4f90 in group travelportal.readers.bonusgroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 15:00:38,991] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.bonusgroup in state PreparingRebalance with old generation 16 (__consumer_offsets-32) (reason: removing member consumer-travelportal.readers.bonusgroup-2-6bf229e1-9b99-4813-9b65-69152fdc4f90 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 15:00:38,999] INFO [GroupCoordinator 0]: Group travelportal.readers.bonusgroup with generation 17 is now empty (__consumer_offsets-32) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 15:00:43,102] INFO [GroupCoordinator 0]: Member consumer-travelportal.readers.statgroup-2-168d4ca9-e8da-4d66-b9e9-7f1c3d2fdbff in group travelportal.readers.statgroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 15:00:43,102] INFO [GroupCoordinator 0]: Preparing to rebalance group travelportal.readers.statgroup in state PreparingRebalance with old generation 11 (__consumer_offsets-23) (reason: removing member consumer-travelportal.readers.statgroup-2-168d4ca9-e8da-4d66-b9e9-7f1c3d2fdbff on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-12-29 15:00:43,103] INFO [GroupCoordinator 0]: Group travelportal.readers.statgroup with generation 12 is now empty (__consumer_offsets-23) (kafka.coordinator.group.GroupCoordinator)
